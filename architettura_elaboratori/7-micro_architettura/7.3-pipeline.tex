\section{Pipeline}
Il processore \textbf{pipeline} si organizza (al livello logico) più moduli in grado eseguire le
fasi di fetch, decode ed execute sfruttando il parallelismo di tipo temporale.

Come già anticipato nel capitolo \ref{ch: parallelismo}, una volta che riusciamo a far lavorare
tutti i moduli contemporaneamente andiamo \emph{a regime} e questo ci permette di ottenere un
risultato di un'istruzione ogni ciclo di clock.

Chiariamo che anche il processore single cycle esegue termina un'istruzione per ogni ciclo di clock
ma ha un ciclo di clock più lungo. Semplificando, dividiamo un processore pipeline in tre moduli,
uno per il fetch, uno per il decode e uno per l'execute e supponiamo che tutti e tre impieghino lo
stesso tempo per terminare.

Così facendo possiamo immaginarci di ridurre il ciclo di clock ad $1 / 3$ del ciclo di clock di un
processore single cycle.

Questo tipo di architettura porta con se delle complicazioni legati principalmente alla separazione
dei moduli e all'introduzione del parallelismo.
\begin{itemize}
	\item Ci sono più stadi che nello specifico sono, fetch, decode, execute, passaggio dalla
	      memoria e fase di \emph{write back} in cui andiamo a scrivere i risultati dell'esecuzione
	      nei registri.
	\item Possono esserci \textbf{dipendenze} tra i dati. Per esempio se andiamo ad eseguire se
	      abbiamo un'istruzione \verb|CMP| seguita da una \verb|BEQ|, dobbiamo andare a settare
	      i flags di condizione prima che avvenga la decodifica dell'istruzione \verb|BEQ|.
\end{itemize}
In un processore pipeline abbiamo di nuovo la memoria istruzioni e la memoria dati separate ma,
similmente al processore multi-cycle, abbiamo diverse zone del circuito separate da registri.
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.7] {circuiti/pipeline.svg}
\end{center}
Come possiamo vedere dall'immagine, i registri colorati servono proprio separare le varie fasi di
elaborazione.

Nell'immagine manca l'unità di controllo che è molto più complessa rispetto a quella vista in
precedenza e gioca un ruolo chiave per il funzionamento corretto del processore pipeline.

\subsection{Dipendenze}
Si ha un problema di \textbf{dipendenza} tra le istruzioni quando una certa unità deve leggere un
dato che ancora non è stato prodotto da un'altra unità. Tale dipendenza prende il nome di
\textbf{Read After Write}, la quale ci dice che dobbiamo leggere solo dopo aver scritto il dato
corretto. Questo tipo di dipendenza si verifica ad esempio con istruzioni di tipo condizionale,
come ad esempio
\begin{minted}{gas}
cmp r1, r2
beq end
\end{minted}
Nel caso single cycle, l'esecuzione delle due istruzioni viene iniziata e terminata in due cicli di
clock differenti. In questo modo non si creano situazioni di dipendenza poiché tutto quello che
deve leggere l'istruzione \verb|beq| è stato già scritto al ciclo di clock precedente.
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.8] {circuiti/dipendenze1.svg}
\end{center}
Se non facessimo le opportune modifiche, nel caso pipeline incapperemmo in un problema di
dipendenze non soddisfatte. Se eseguissimo le stesse istruzioni in processore pipeline avremmo una
situazione di questo tipo
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.8] {circuiti/dipendenze2.svg}
\end{center}
Come possiamo vedere, durante il secondo ciclo clock ci ritroviamo in una situazione in cui
vogliamo decodificare l'istruzione \verb|beq| ma la \verb|cmp| non ha ancora scritto i flag
necessari, che invece andrà a scrivere alla fine del ciclo di clock.

Le due principali soluzioni sono il \textbf{forwarding} e creare situazioni di \textbf{stallo}.
Dato che i flag in uscita dalla ALU vengono scritti nel registro \verb|CPSR| e solo al giro di
clock successivo verrebbero trasmessi all'unità di controllo per effettuare correttamente la fase
di decodifica, potremmo creare un collegamento che manda l'uscita della ALU direttamente all'unità
di controllo gestendo le due casistiche tramite un multiplexer.

Il forwarding complica un po' il circuito ed è per questo che si è pensato di provocare degli
stalli. Uno stallo è uno \textbf{stop} momentaneo del funzionamento del pipeline nel momento in
cui, in un certo stadio, produciamo qualcosa di necessario ad uno degli stadi precedenti per
funzionare correttamente.

\subsubsection{Stalli}
In sostanza blocchiamo il passaggio del risultato da un certo stadio al successivo finché non
abbiamo scritto le informazioni necessarie nello stadio che ne ha bisogno. Nel frattempo gli stadi
in attesa ricevono un segnale \verb|WE| a 0 impedendo quindi di andare avanti nel processo,
rallentando tutta la catena.
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.8] {circuiti/stallo.svg}
\end{center}
In questo caso blocchiamo l'istruzione \verb|beq| nello stadio di fetch poiché, per eseguire una
decodifica corretta abbiamo bisogno che i flag di condizione siano scritti correttamente.

Per riuscire ad implementare gli stalli si aggiunge un modulo detta \textbf{hazard unit} che
gestisce, un po' come l'unità di controllo, i segnali di \verb|WE| e bit di controllo appositamente
nei casi di stallo. L'hazard unit ci è utile anche per implementare del forwarding come nel caso in
cui volessimo eseguire il seguente codice
\begin{minted}{gas}
ldr r0, [r1]
add r1, r0, r2
\end{minted}
avremmo una dipendenza tra le due istruzioni poiché per eseguire la \verb|add| dovremmo aspettare
che il valore \verb|r0| sia stato caricato e scritto nel modulo \verb|REG|. Come possiamo notare
dallo schema del processore pipeline, dal momento in cui ricaviamo il valore di \verb|r0| dalla
memoria dati a quando lo andiamo a scrivere in \verb|REG| passano diversi cicli di clock.

Quello che possiamo fare, aiutandoci con l'hazard unit è inviare il valore \verb|r0| direttamente
ad uno degli ingressi della ALU permettendoci così di eseguire la \verb|add| un ciclo di clock in
anticipo.

\begin{tcolorbox}
	Possiamo quindi dire che il processore pipeline è riceve i segnali in modo ritardato dall'unità
	di controllo, poiché ogni volta questi devono attraversare i vari registri. Una volta
	attraversato un registro, i segnali diventano disponibili alla parte successiva al registro.
\end{tcolorbox}

Considerando ancora l'esempio appena fatto l'operazione \verb|beq| è subito dopo \verb|cmp| ma, in
generale potrebbe essere eseguita più avanti. A seconda dei casi potremmo aver bisogno di provocare
uno stallo o meno.

Se per esempio dopo la \verb|cmp| avremmo delle semplici operazioni aritmetiche non sarebbe
necessario uno stallo poiché i flags sarebbero già stati scritti e una volta arrivato il momento di
eseguire la \verb|beq| avremmo già tutto ciò che ci serve.

Questo tipo di ottimizzazioni possono essere fatte sia dal programmatore che dal compilatore che,
tramite alcune regole, cambia l'ordine delle istruzioni, senza alterare la semantica del programma,
in modo da evitare il più possibile gli stalli e non sprecare cicli di clock. Il codice
\begin{minted}{gas}
mov r0, #0
cmp r1, r2
beq end
\end{minted}
è equivalente a
\begin{minted}{gas}
cmp r1, r2
mov r0, #0
beq end
\end{minted}
ma nel primo caso creiamo uno stallo e nel secondo caso no. Per capire se possiamo cambiare
l'ordine di alcune istruzioni consideriamo un insieme di due istruzioni \verb|istr1| e \verb|istr2|
e consideriamo
\begin{gather*}
	R_1 = \{ \text{registri letti da istr1} \} \\
	W_1 = \{ \text{registri scritti da istr1} \} \\
	R_2 = \{ \text{registri letti da istr2} \} \\
	W_2 = \{ \text{registri scritti da istr2} \}
\end{gather*}
Possiamo invertire l'ordine di esecuzione di \verb|istr1| e \verb|istr2| senza alterare la
semantica del programma se e solo se valgono le seguenti tre regole
\begin{gather*}
	R_1 \cap W_2 = \emptyset \\
	W_1 \cap R_2 = \emptyset \\
	W_1 \cap W_2 = \emptyset
\end{gather*}
Queste sono dette \textbf{condizioni di Bernstein} sono sfruttate dai compilatori per effettuare
ottimizzazioni in modo da evitare, per quanto possibile gli stalli.

\subsubsection{Dipendenze di controllo}
Quando effettuiamo delle istruzioni di salto, dobbiamo andare ad modificare il valore del program
counter. A tal proposito l'istruzione viene decodificata e sarà poi la ALU a produrre il nuovo
valore.

Il problema è che nel frattempo, il program counter è andato avanti normalmente avviando il fetch e
la decodifica delle istruzioni successive al salto (quello immediatamente sotto al salto). Eseguire
in modo parziale queste istruzioni non è problema, l'importante è disabilitare i segnali di
\verb|WE| della memoria e/o del register file, di modo che i risultati non vengano consolidati.

Come possiamo vedere, le istruzioni di salto consumano un intero ciclo fetch-decode-execute per la
loro esecuzione andando a creare una \textbf{dipendenza di controllo} senza permettere il normale
funzionamento pipeline.

L'effetto di un salto è detto \textbf{flush} di quattro istruzioni, in quanto tali istruzioni
vengono eseguite ma non si consolida il risultato.

Ancora una volta possiamo creare un'uscita dalla ALU che, non appena calcola l'offset del salto
rimanda indietro il risultato (forwarding) permettendoci di ridurre il flush da quattro a due
istruzioni.

Ancora una volta introduciamo un modulo (\textbf{control hazard}) che gestisce i segnali dei vari
multiplexer e di \verb|WE|.

Fino ad ora abbiamo sostanzialmente definito n stadi del pipeline: fetch, decode, execute, lettura
o scrittura nella memoria dati e \emph{write back}.

Ognuna di queste operazioni può essere messa in pipeline a sua volta, per esempio mettendo in
pipeline le operazioni interne alla ALU.

Questo ci permette di aumentare le prestazioni, un po' come abbiamo visto nel multi-cycle, poiché
aumentiamo gli stadi del pipeline per riuscire ad accorciare il clock e generando un throughput
maggiore.

Il problema è che in questo modo aumenta anche il peso delle dipendenza poiché ci saranno più
istruzioni che saranno contemporaneamente in uno degli stadi del pipeline e che quindi
richiederanno di leggere o scrivere dei registri comuni. Abbiamo quindi bisogno di una hazard unit
più complessa.

\subsection{Micro-operazioni}
Un modo per rendere la progettazione delle varie unità di controllo più facile è tramite la
definizione di un insieme di \textbf{$\mu$-operazioni}. Molte delle istruzioni assembler che
abbiamo visto non sono $\mu$-operazioni, ad esempio
\begin{minted}{gas}
ldr r1, [r2], r3
\end{minted}
è equivalente ad eseguire le due $\mu$-operazioni
\begin{minted}{gas}
ldr r1, [r2]
add r2, r2, r3
\end{minted}
Interpretare ed eseguire un insieme di $\mu$-operazioni è molto conveniente in quanto la decodifica
di molte delle istruzioni corrisponde a più $\mu$-operazioni. Un esempio classico di
$\mu$-operazione è l'incremento del \verb|PC| di 4, che non viene mai esplicitato ma viene eseguito
per ogni istruzione diversa da un salto.

Un insieme di $\mu$-operazioni scelto bene permette una semplificazione significativa di dell'unità
di controllo in quanto è necessario implementare solo i segnali di controllo e \verb|WE| per
operazioni più basilari di quelle composte come una \verb|ldr| con post-incremento.

\subsection{Predizione dei salti}
Il sistema di \textbf{predizione dei salti} serve ad alleggerire il peso delle dipendenze di
controllo cercando di capire se un salto condizionato verrà effettuato o no. Si aggiunge un po' di
logica per memorizzare direzione, target del salto e se è stato già preso oppure no.

Memorizzando il target non abbiamo bisogno di andare a calcolare l'offset ma possiamo modificare
direttamente il \verb|PC| evitando il flush delle istruzioni causato dalle dipendenze di controllo.

Il sistema di predizione è implementato tramite un automa a quattro stati che rappresentano la
nostra predizione: forse preso, sicuramente preso, forse non preso, sicuramente non preso.
\begin{center}
	\begin{tikzpicture}[
			scale = 0.8,
			->, >=Stealth,
			node distance=3cm,
			main node/.style={circle, draw, thick, font=\Large}
		]
		\node[state, main node] (SP) {SP};
		\node[state, main node] (FP) [right of=SP] {FP};
		\node[state, main node] (FNP) [below of=FP] {FNP};
		\node[state, main node] (SNP) [left of=FNP] {SNP};

		\draw
		(FP) edge[bend right] node[->, above, black] {preso} (SP)
		(SP) edge[bend right] node[->, above, black] {non preso} (FP)
		(FP) edge[bend left] node[->, right, black] {non preso} (FNP)
		(FNP) edge[bend left] node[->, below, black] {non preso} (SNP)
		(FNP) edge[bend left] node[->, left, black] {preso} (FP)
		(SNP) edge[bend left] node[->, below, black] {preso} (FNP);
	\end{tikzpicture}
\end{center}
Come possiamo vedere ogni volta che il salto viene preso o non preso ci muoviamo in una stato che
rappresenta la probabilità che in un certo momento il salto venga preso o non preso.

Ovviamente questo sistema \emph{cerca} di predire i salti ma potrebbe sbagliare e, in tal caso,
dobbiamo essere pronti a riparare all'errore prima di scrivere i registri. A tal proposito possiamo
introdurre ritardi tramite stalli oppure scrivere in registri temporanei per poi scrivere su
registri significativi solo dopo aver avuto la certezza sull'esito del salto.

Supponiamo di voler eseguire il seguente codice
\begin{minted}{gas}
main:
	beq target
	add r2, r1, #2
	sub r2, r2, #1
target:
	ldr r1, r3
\end{minted}
e supponiamo che il sistema di predizione ci dica che il salto vada preso. Se la predizione è
sbagliata e scriviamo \verb|r1| prima di rendercene conto abbiamo un errore. Per risolvere possiamo
\begin{itemize}
	\item azzerare il segnale di \verb|WE| prima che \verb|ldr| faccia l'operazione di write back.
	\item scrivere il valore raccolto da \verb|ldr| in un registro temporaneo e poi trasferire il
	      valore in \verb|r1| solo se abbiamo la certezza che la predizione è stata corretta.
\end{itemize}
In ogni caso sbagliare un salto ci fa sprecare cicli di clock ma non più di quelli sprecati per
eventuali flush o stalli. In compenso predire correttamente il salto ci permette di mantenere
attivo il flusso del pipeline.