\chapter{Numeri primi}\label{primi}
Iniziamo ora a parlare di \textbf{primalit\`a} e di come costruire algoritmi efficienti per effettuare il
\textbf{test di primalit\`a}, ossia algoritmi in grado di dirci se un numero \`e primo o no e come fare per generare
numeri primi.

Iniziamo con un algoritmo semplice ma che come vedremo risulter\`a molto inefficiente.
\begin{lstlisting}[style=pseudo-style]
Primo(n)
	for i = 2 to sqrt(n)
		if n % i == 0 then
			return false;
	
	return true;
\end{lstlisting}
Come possiamo facilmente constatare, l'algoritmo
\begin{enumerate}
	\item Controlla se uno dei numeri da 2 a $\sqrt{n}$ divide $n$. Si parte da 2 dato che la divisione per 0 \`e in
	      generale indefinita o comunque tende all'infinito e tutti i numeri sono divisibili per 1.

	      Ci si ferma a $\sqrt{n}$ dato che un numero, se composto, possiede sicuramente un divisore minore della sua
	      radice.
	\item Se ne trova uno che divide $n$ allora ritorna \verb|false|.
	\item Se non ne trova nessuno ritorna \verb|true|.
\end{enumerate}
Un'analisi poco attenta potrebbe indurci a pensare che il costo di questo algoritmo sia $O(\sqrt{n})$ dato che faccio al
pi\`u $\sqrt{n}$ iterazioni. Questo \`e in parte vero ma dobbiamo considerare la dimensione dell'istanza di input, la
sua rappresentazione e il costo della divisione.

L'istanza di input, ossia $n$, richiede $\Theta(\log_2 n)$ bit per essere rappresentata mentre la divisione \`e, in
generale, un'operazione quadratica nel numero di cifre. Tutto questo fa salire la complessit\`a a
\[ O(\sqrt{n} \cdot \log^2 n) \]
Ma non \`e finita qui: come abbiamo detto, $n$, necessita di $\Theta(\log_2 n)$ bit per essere rappresentato, dunque $n$
si pu\`o scrivere come $2^{\log n}$ e questo fa diventare la complessit\`a
\[ O(2^\frac{\log n}{2} \cdot \log^2 n) \]
Come possiamo vedere, un algoritmo all'apparenza polinomiale \`e in realt\`a un algoritmo di costo esponenziale nella
dimensione dell'input. Si tratta di un algoritmo \textbf{pseudopolinomiale}.

\section{Algoritmo di esponenziazione veloce}\label{esponenziazione}
Introduciamo l'\textbf{algoritmo di esponenziazione veloce} o \textbf{algoritmo delle quadrature successive} che sar\`a
molto utile per svolgere elevamenti a potenza in modo efficiente. Essere in grado di svolgere elevamenti a potenza
in modo efficiente \`e necessario per avere algoritmi efficienti per il test di primalit\`a.

Sia $b$ la base e $n$ l'esponente e $m$ un intero qualsiasi, vogliamo calcolare
\[ x = b^n \mod{m} \]
con un numero di operazioni dell'ordine di $O(\log_2 n)$.
\begin{enumerate}
	\item Si scompone l'esponente $n$ come somma di potenze di 2.
	      \[ n = \sum_{i=0}^{\lfloor \log_2 n \rfloor} k_i \cdot 2^i \quad \quad k_i \in \{0,1\} \]
	\item Si calcolano tutte le potenze $b^{2^i} \mod{m}$ calcolando ogni potenza come quadrato delle precedente
	      \[ b^{2^i} \mod{m} = \left( b^{2^{i-1}} \right)^2 \mod{m} \]
	      con $1 \leq i \leq \lfloor \log_2 n \rfloor$
	\item Prendiamo, fra le potenze ricavate al punto 2, quelle che compaiono nella scomposizione fatta al
	      punto 1 e moltiplichiamole
	      \[ x = \prod_{i \mid k_i \neq 0} b^{2^i} \mod{m} \]
\end{enumerate}

Al punto 2 vengono compiute esattamente $\log_2 n$ operazioni per il calcolo delle varie potenze e al punto 3 svolgiamo
un numero di moltiplicazioni dell'ordine di $O(\log_2 n)$.

Se consideriamo che la moltiplicazione \`e un'operazione di costo polinomiale nel numero delle cifre \`e facile
stabilire che l'algoritmo sia complessivamente di costo polinomiale.

\begin{example}
	Vogliamo calcolare
	\[ 9^{45} \mod{11} \]
	Scriviamo l'esponente come somma di potenze di 2
	\[ 9^{32 + 8 + 4 + 1} \mod{11} \]
	Calcoliamo ora le potenze $9^{2^i}$ fino ad arrivare a $9^{32}$, ognuna calcolata come quadrato della precedente.
	\[
		\begin{matrix}
			9^2 \mod{11} =    &                & 4 \\
			9^4 \mod{11} =    & 4^2 \mod{11} = & 5 \\
			9^8 \mod{11} =    & 5^2 \mod{11} = & 3 \\
			9^{16} \mod{11} = & 3^2 \mod{11} = & 9 \\
			9^{32} \mod{11} = & 9^2 \mod{11} = & 4
		\end{matrix}
	\]
	Ora non ci rimane che prendere le potenze di cui abbiamo bisogno
	\[ 9^{45} \mod{11} = (9^{32} \mod{11}) \cdot (9^8 \mod{11}) \cdot (9^4 \mod{11}) \cdot (9^1 \mod{11}) \]
	che possiamo comodamente riscrivere come
	\[ 9^{45} \mod{11} = 4 \cdot 3 \cdot 5 \cdot 9 = 1 \]
\end{example}

\section{Algoritmi randomizzati}\label{algoritmi_random}
Gli algoritmi randomizzati sono fondamentali per effettuare test di primalit\`a efficienti dato che un algoritmo
deterministico e polinomiale nella dimensione dell'input esiste ma \`e comunque molto lento.

Questi algoritmi si dividono in due gruppi principali
\begin{itemize}
	\item \textbf{Las Vegas}: generano un risultato \emph{sicuramente corretto} in un tempo \emph{probabilmente breve}.
	\item \textbf{Monte Carlo}: generano un risultato \emph{probabilmente corretto} in un tempo \emph{sicuramente breve}.
\end{itemize}
L'algoritmo che vedremo per il test di primalit\`a \`e della tipologia Monte Carlo ma la probabilit\`a di errore
dev'essere \textbf{misurabile} e \textbf{arbitrariamente piccola}.

\subsection{Classe RP}
La \textbf{classe RP} comprende tutti quei problemi \emph{verificabili} in tempo polinomiale tramite algoritmi
randomizzati.

Sia $\Pi$ un problema decisionale, $x$ un istanza di input di $\Pi$ allora $y$ \`e un \textbf{certificato probabilistico}
di $x$ se
\begin{itemize}
	\item \`E di lunghezza al pi\`u polinomiale in $|x|$ (devo leggerlo in tempo polinomiale).
	\item \`E estratto perfettamente a caso da un insieme associato a $x$.
\end{itemize}
Possiamo anche dire che $A$ \`e un \textbf{algoritmo di verifica} che prende in input $x$ e $y$ se, in tempo polinomiale,
riesce ad attestare che
\begin{itemize}
	\item $x$ non possiede la propriet\`a.
	\item $x$ possiede la propriet\`a con probabilit\`a $> 1/2$.
\end{itemize}
Si congettura che
\[ \text{P} \subset \text{RP} \subset \text{NP} \]

\section{Test di Miller-Rabin}\label{Miller_Rabin}
La prima parte dell'algoritmo \`e composta dei seguenti passi.
\begin{enumerate}
	\item Prendiamo $n$ intero e dispari di cui vogliamo testare la primalit\`a.
	\item Prendiamo $n-1$ (sicuramente pari) e cerchiamo la massima potenza di 2 che lo divide, cos\`i da rappresentare
	      $n-1$ in questo modo
	      \[ n-1 = 2^w \cdot z \quad \text{con $z$ dispari} \]
	      questo \`e sempre possibile perch\'e un numero pari \`e sempre rappresentabile come potenza di 2 che moltiplica
	      un numero dispari.

	      Per determinare $w$ e $z$ impieghiamo in media $O(\log n)$ passi.
	\item Scegliamo un intero $y$ compreso tra 2 e $n-1$.
\end{enumerate}
Se $n$ \`e primo allora valgono i due predicati
\begin{itemize}
	\item $(n, y) = 1$
	\item $y^z \mod{n} \equiv 1$

	      oppure

	      $\exists i, \quad 0 \leq i \leq w-1 \mid y^{2^i} \cdot z \mod{n} \equiv -1$
\end{itemize}
Chiariamo che questi due predicati sono condizioni necessarie alla primalit\`a ma non sufficienti.

\begin{lemma}[Miller-Rabin]
	Se $n$ \`e un numero composto, il numero di interi $y$ compresi tra 2 ed $n-1$, che soddisfano entrambi i predicati
	\`e minore di $n / 4$.
	\[ \# \{ 2 \leq y \leq n-1 \mid P_1(y) = \text{ true} \quad \wedge \quad P_2(y) = \text{ true} \} < \frac{n}{4} \]
\end{lemma}
Questo lemma ci dice che la probabilit\`a di scegliere un $y$ che soddisfa entrambi i predicati \`e minore di $1 / 4$.
Questo \`e banale dato che ho $n - 2$ possibili scelte e $n / 4$ di queste rendono veri entrambi i predicati.
\[ \frac{n/4}{n-2} < \frac{1}{4} \]
Quando scelgo un $y$ vado a testare i due predicati: se anche solo uno \`e falso allora possiamo affermare con certezza
che $y$ \`e composto, se invece sono entrambi soddisfatti \emph{molto probabilmente} \`e primo con probabilit\`a di
errore al pi\`u del $25\%$.

A questo punto possiamo iterare $k$ volte con $k$ scelte casuali e indipendenti di $y$, la probabilit\`a di errore scende
a $(1/4)^k$.

Possiamo quindi concludere l'algoritmo in questo modo
\begin{enumerate}
	\setcounter{enumi}{3}
	\item Verifico che i due predicati siano soddisfatti.
	\item Itero $k$ volte su $k$ scelte diverse e casuali di $y$.
	      \begin{itemize}
		      \item Se anche solo una volta un predicato non \`e soddisfatto allora il numero non \`e primo.
		      \item Altrimenti possiamo affermare che lo sia con probabilit\`a di errore inferiore a $(1/4)^k$
	      \end{itemize}
\end{enumerate}

\begin{lstlisting}[style=pseudo-style]
Verifica(n, y) // true se n e' composto
	if not P1(n, y) or not P2(n, y) then
		return false;
	else
		return true;
\end{lstlisting}

\begin{lstlisting}[style=pseudo-style]
TestMR(n, k)
	for i = 1 to k
		y = random(2, n - 1);
		if Verifica(y, n) then 
			return false;

	return true;
\end{lstlisting}

\subsection{Verifica dei predicati}
Possiamo valutare il costo del ciclo come costante ($k$ cicli) mentre \`e fondamentale capire il costo della verifica
dei predicati.
\begin{itemize}
	\item Per la verifica del primo predicato dobbiamo calcolare il massimo comun divisore con l'algoritmo di Euclide.
	      Un'operazione che richiede costo cubico nel numero di cifre
	      \[ O(\log^3 n) \]
	\item La verifica del secondo predicato \`e pi\`u complessa per via degli elevamenti a potenza.

	      Prima di tutto dobbiamo calcolare $y^z$ e per capire quanto sia costosa questa operazione dobbiamo capire quanto
	      \`e grande $z$. Se andiamo a vedere come si ottiene $z$ possiamo ricavare che $z$ abbia al massimo valore
	      $\frac{n-1}{2}$ dunque $z$ \`e dell'ordine di $n$.

	      Per fare quindi $y^z$ non posso moltiplicare $y$ per se stesso $\frac{n-1}{2}$ volte perch\'e farei un numero
	      di operazioni proporzionale al valore $n$ e non possiamo permettercelo in termini computazionali.

	      Il nostro obbiettivo \`e quello di compiere un numero di operazioni che \`e proporzionale al numero delle cifre
	      ossia $\log_2 n$ e come sappiamo, questo si pu\`o fare con l'\textbf{algoritmo di esponenziazione veloce},
	      esposto al paragrafo \ref{esponenziazione}.

	      Per la verifica della seconda parte del predicato basta semplicemente elevare al quadrato il risultato ottenuto
	      per la verifica della prima parte del predicato. Anche questa seconda verifica ha quindi costo polinomiale.
\end{itemize}
Come possiamo vedere, la verifica dei predicati, ha complessivamente costo polinomiale.

\section{Generazione di numeri primi}\label{generazione_primi}
La generazione di numeri primi casuali si effettua semplicemente generando un numero casuale e in seguito si effettua
il test di primalit\`a di Miller-Rabin. Ripeto la generazione del numero casuale finch\'e non ne trovo uno che posso
dichiarare primo con un possibilit\`a di errore pi\`u bassa possibile.

\begin{theorem}
	Il numero di numeri primi minori di un certo $n$ tende a
	\[ \frac{n}{\ln n} \]
	per $n$ che tende all'infinito.
\end{theorem}

Questo teorema ci dice che, per $n$ sufficientemente grande, nel suo intorno (di ampiezza $\ln n$) cade mediamente un
numero primo.

Mediamente dovremo quindi fare un numero $\ln n$ di tentativi, il che ci va bene dato che \`e polinomiale nel numero
delle cifre.

\subsection{Algoritmo}
Costruiamo ora un algoritmo per generare un numero primo di $n$ bit.

\begin{lstlisting}[style=pseudo-style]
Primo(n)
	S = randomSeq(n-2); // sequenza casuale di n-2 bit
	N = 1 + S + 1; // numero dispari con n bit significativi
	while TestMR(N, k) == 0 
		N = N + 2;

	return N;
\end{lstlisting}
Il costo complessivo \`e $O(n^4)$ dato che facciamo $O(n)$ volte il test di Miller-Rabin, il quale aveva un costo
complessivamente di $O(n^3)$.
