\chapter{Forme di parallelismo}\label{ch: parallelismo}
Al fine di ottimizzare le performance del processore si è passati ad un paradigma che introduce il
\textbf{parallelismo} nella gestione delle istruzioni da eseguire. Le forme di parallelismo
principali sono sostanzialmente due: \textbf{spaziale} e \textbf{temporale}.

\section{Parallelismo spaziale}
L'idea in questo caso è quella di suddividere il lavoro in più parti (\textbf{task}), ciascuna
calcolata da un \textbf{worker}. In generale possiamo dire che se dobbiamo eseguire $m$ task e
abbiamo a disposizione $n$ worker, per completare tutti i task ci metteremo un tempo pari a
\[ T_\text{par} (n) = \frac{m}{n} \cdot t \]
dove $t$ è il tempo di completamento di un singolo task.

Il parallelismo spaziale può essere suddiviso in due ulteriori tipologie: \textbf{map} e
\textbf{farm}. Nel caso in cui i task siano parte di un problema più grande e quindi coesistono
tutti allo stesso tempo, allora parliamo di map.

Nel caso in cui i task esistano in tempo diversi, per esempio arrivando uno dopo l'altro e che
quindi possono non essere in alcun modo correlati tra di loro, allora parliamo di farm. In questo
caso possiamo ad esempio affidarci ad uno \textbf{scheduler} in grado di assegnare, man mano che
arrivano, i vari task ai worker liberi.

Una grandezza in gioco per valutare l'aumento delle performance di un sistema parallelo è lo
\textbf{speed-up}, il quale è calcolato come segue
\[ \text{speed-up} (n) = \frac{T_\text{seq}}{T_\text{par} (n)} \]
dove $T_\text{seq}$ è il tempo che impiegheremmo con un calcolo sequenziale. Nel caso di
parallelismo spaziale avremmo uno speed-up pari a
\[ \text{speed-up} (n) = \frac{m \cdot t}{\frac{m}{n} \cdot t} = n \]
Altre grandezze in gioco sono la \textbf{latenza}, definita come il tempo assoluto di lavoro per il
calcolo di un risultato e il \textbf{throughput}, definito come il numero di task terminati
nell'unità di tempo.

Quest'ultimo è definito in funzione del \textbf{tempo di servizio}, ossia il tempo che intercorre
tra il termine di un task e il termine di un task successivo (in questo caso equivale a $t$).
\[ \text{Throughput} = \frac{1}{T_s} \]
Analogamente al throughput c'è il \textbf{tempo di completamento}, definito come il tempo di
completamento di tutti i lavori. Se definiamo quindi $t_0$ come il tempo di inizio del primo task
e $t_1$ come il tempo di fine dell'ultimo task, il tempo di completamento equivale a
\[ T_c = t_1 - t_0 \]
Nel caso di farm, avremmo un tempo di completamento pari a
\[ T_c = T_\text{sched} \cdot m + \frac{m}{n} \cdot t \approx \frac{m}{n} \cdot t \]
dove $T_\text{sched}$ è il tempo che lo schedulatore impiega ad assegnare i task. In genere questo
tempo è trascurabile e dunque l'approssimazione fatta sopra è lecita.

Nel caso invece di map dobbiamo considerare che c'è un momento in cui si suddivide il problema in
parti più piccole $T_\text{split}$ e un momento in cui si uniscono i risultati prodotti dai singoli
worker per generare il risultato finale $T_\text{merge}$. Avremo quindi un tempo di completamento
pari a
\[ T_c = T_\text{split} + \frac{m}{n} \cdot t + T_\text{merge} \]
ma ancora una volta consideriamo $T_\text{split}$ e $T_\text{merge}$ come trascurabili e dunque
avremmo un tempo di completamento pari a
\[ T_c \approx \frac{m}{n} \cdot t = \frac{T_\text{seq}}{n} \]
Il parallelismo spaziale è quello implementato dai processori superscalari.
