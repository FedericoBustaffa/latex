\part{Calcolo delle probabilità}

\chapter{Calcolo delle probabilità e indipendenza}
Il calcolo delle \textbf{probabilità} ci serve per la costruzione di un modello
\textbf{statico inferenziale}, il quale unisce statistica descrittiva e probabilità per descrivere
la realtà. Prima di addentrarci nei formalismi matematici introduciamo qualche concetto.
\begin{itemize}
	\item Quello che vogliamo calcolare è la probabilità che un certo \textbf{evento} accada. Il
	      concetto
	      di evento non si può formalizzare, ma possiamo fare qualche esempio: se lanciamo un dado,
	      il fatto che esca 6 è un evento.
	\item Il secondo concetto è quello di \textbf{casuale} o \textbf{aleatorio}
	      (\textbf{stocastico}). Queste tre parole hanno quasi lo stesso significato ma possiamo
	      generalizzare dicendo che significano \emph{"dovuto al caso"}. Più avanti introdurremo
	      altri termini come \emph{variabili aleatorie} e \emph{indipendenza stocastica}.
\end{itemize}
Due dei problemi che andremo a trattare sono:
\begin{itemize}
	\item La \textbf{rappresentazione} degli eventi.
	\item Quali \textbf{proprietà} devono soddisfare le probabilità.
\end{itemize}
Per riuscire a capire meglio tutti questi concetti sarà necessario anche conoscere qualche nozione
di base sulle serie.

\section{Spazi di probabilità}
Possiamo vedere tutti gli esiti possibili di un esperimento come un insieme, detto
\textbf{spazio campionario}, che indicheremo con $\Omega$.

Quando facciamo delle invece \emph{affermazioni} su tali eventi stiamo (in linea generale)
restringendo lo spazio di campionario e ne stiamo considerando quindi dei sottoinsiemi, detti
\textbf{eventi}.

Se invece facciamo riferimento a singoli eventi appartenenti ad un insieme si parla di
\textbf{eventi elementari} e sono sia gli elementi $\omega$ in $\Omega$ sia gli insiemi singoletto
$\{\omega\}$.

\begin{example}
	Consideriamo ad esempio 2 lanci di moneta, e assegnamo il valore 1 a testa e 0 a croce. Abbiamo
	che
	\[ \Omega = \{ (0,0), (0,1), (1,0), (1,1) \} \]
	rappresenta tutti possibili esiti di 2 lanci di moneta. E un evento elementare è per esempio
	$(0,1)$. Con l'affermazione "\emph{è uscita almeno una testa}" stiamo considerando un
	sottoinsieme $A$ di $\Omega$ definito come segue
	\[ A = \{ (0,1), (1,0), (1,1) \} \]
	definendo quindi un sottoinsieme di eventi.
\end{example}

Dato che possiamo vedere gli spazi campionari come insiemi di eventi, è facile trovare una
correlazione tra le operazioni insiemistiche e i connettivi logici.
\begin{itemize}
	\item $A \cup B =$ \verb|A OR B|
	\item $A \cap B =$ \verb|A AND B|
	\item $A^c = $ \verb|NOT A|
	\item $A \backslash B =$ \verb|A AND NOT B|
	\item $A \subseteq B =$ \verb|A implica B|
\end{itemize}
Aggiungiamo inoltre che se $A \cap B = \emptyset$ allora si dice che $A$ e $B$ sono
\textbf{disgiunti}.

\begin{example}
	Se lanciamo un dado a 6 facce abbiamo
	\[ \Omega = \{ 1, 2, 3, 4, 5, 6 \} \]
	L'insieme degli eventi tali che il numero uscito sia
	\begin{itemize}
		\item Pari è $A = \{ 2, 4, 6 \}$
		\item Pari e maggiore di 3 è $A \cap B = \{ 4, 6 \}$
		\item Pari ma non maggiore di 3 è $A \backslash B = A \cap B^c = \{2\}$
		\item Sia pari che dispari è $A \cap A^c = \emptyset$
	\end{itemize}
\end{example}

Ora possiamo gestire gli eventi legati da connettivi logici tramite operazioni insiemistiche
equivalenti.

Vogliamo quindi definire una classe di eventi che sia chiusa per le operazioni insiemistiche
appena menzionate, ovvero vogliamo che le operazioni insiemistiche tra eventi producano ancora
degli eventi. Questo è banale se consideriamo tutti i sottoinsiemi di $\Omega$, ossia le
\textbf{parti} di $\Omega$, indicati con $\mathcal{P}(\Omega)$, ma in generale non è sempre
possibile.

\begin{definition}
	Sia $\Omega \neq \emptyset$ e $\F \subseteq \mathcal{P}(\Omega)$ una famiglia di sottoinsiemi
	di $\Omega$. Diciamo che $\F$ è un'\textbf{algebra di parti} se
	\begin{itemize}
		\item $\Omega, \emptyset \in \F$
		\item $\F$ è stabile per la complementazione: se $A \in \F$ allora $A^c \in \F$
		\item $\F$ è stabile per unione finita, ovvero se $A_1, A_2, \dots, A_n \in \F$ allora
		      anche la loro unione $\cup_{i=1}^n A_i$ appartiene a $\F$.
	\end{itemize}
	Se inoltre $\Omega$ e una sua algebra di parti $\F$ hanno infiniti elementi, diciamo che $\F$
	è una $\sigma$\textbf{-algebra} se soddisfa l'ipotesi addizionale:
	\begin{itemize}
		\item $\F$ è stabile per unione numerabile, ovvero se esiste una successione di
		      sottoinsiemi $A_1, A_2, \dots$ appartiene a $\F$ anche la loro unione
		      $\cup_{i=1}^\infty A_i$ appartiene a $\F$.
	\end{itemize}
\end{definition}

La $\sigma$-algebra $\F$ è quindi un insieme chiuso per tutte le operazioni insiemistiche viste
sopra ed è la classe degli eventi \emph{ammissibili}.

\subsection{Funzione di probabilità}
La \textbf{probabilità} $P$ di un evento $A \in \F$ è il grado di fiducia che $A$ si realizzi ed è
compreso tra 0 e 1.

\`E intuitivo che, se due eventi $A$ e $B$ sono disgiunti, allora la probabilità che si realizzi
$A \cup B$ è $P(A) + P(B)$. Questo significa che la probabilità è una funzione d'insieme
\textbf{finitamente additiva}.

Queste prime nozioni servono per dare una definizione più generale e più rigorosa della probabilità
considerando anche i casi in cui dobbiamo trattare infiniti eventi.

\begin{definition}
	Dato $\Omega$ un insieme e $\F$ una $\sigma$-algebra di $\Omega$, la \textbf{probabilità} è
	una funzione
	\[ P : \F \to [0, 1] \]
	tale che
	\begin{itemize}
		\item L'evento certo ha probabilità unitaria: $P(\Omega) = 1$.
		\item Se la successione degli $A_i$ è una successione di elementi di $\F$ a due a due
		      disgiunti, si ha, nel caso in cui la successione sia finita, che
		      \[ P \left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i) \]
		      Se invece la successione è infinita allora vale
		      \[
			      P \left( \bigcup_{i=1}^{+\infty} A_i \right) = \sum_{i=1}^{+\infty} P(A_i) =
			      \lim_{n \to +\infty} \sum_{i=1}^n P(A_i)
		      \]
		      Questa proprietà è detta $\sigma$\textbf{-additività}.
	\end{itemize}
\end{definition}

\begin{definition}
	La terna $(\Omega, \F, P)$ formata da uno spazio campionario, una $\sigma$-algebra ed una
	probabilità $P$ definita su $\F$ viene chiamata \textbf{spazio di probabilità}.
\end{definition}

\paragraph{Proprietà} La probabilità, così come l'abbiamo definita, comporta che
\begin{itemize}
	\item $P(\emptyset) = 0$
	\item $P(A^c) = 1 - P(A)$
	\item $P(A \backslash B) = P(A) - P(B)$
	\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
	\item Caso non banale è quello di $P(A \cup B \cup C)$ in cui abbiamo che
	      \begin{multline*}
		      P(A \cup B \cup C) = P(A) + P(B) + P(C) - \\
		      P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)
	      \end{multline*}
\end{itemize}

\begin{proposition}
	Sia $A \in \F$ una successione infinita, allora si dice che
	\begin{itemize}
		\item $A$ è una successione \textbf{crescente}, cioè $A_i \subseteq A_{i+1}$, $\forall i$
		      se vale $A = \cup_{i=1}^\infty A_i$
		\item $A$ è una successione \textbf{decrescente}, cioè $A_{i+1} \subseteq A_i$,
		      $\forall i$ se vale $A = \cap_{i=1}^\infty A_i$
	\end{itemize}
	In entrambi i casi vale
	\[ P(A) = \lim_{i \to \infty} P(A_i) \]
\end{proposition}

\begin{definition}
	Se $P(A) = 0$ si dice che $A$ è un evento \textbf{trascurabile}.
\end{definition}

\begin{definition}
	Se $P(A) = 1$ si dice che $A$ è un evento \textbf{quasi certo}.
\end{definition}

Facciamo ora qualche considerazione sulla $\sigma$-algebra per capire meglio il perché la abbiamo
definita e perché in precedenza abbiamo detto che non sempre possiamo considerare l'insieme di
tutti gli esiti possibili. Consideriamo $\Omega$ finito o numerabile
\[ \Omega = \{ \omega_1, \omega_2, \dots, \omega_i, \dots \} \]
allora possiamo prendere $\F = \mathcal{P}(\Omega)$ e la probabilità è univocamente determinata
da $p_i = P(\{ \omega_i \})$. Vale infatti che
\[ P(A) = \sum_{\omega_i \in A} p_i \]
Quindi, nel caso $A$ abbia un numero finito di elementi, $P(A)$ equivale alla somma dei $p_i$, se
invece $A$ ha un numero infinito di elementi, $P(A)$ equivale alla serie dei $p_i$.

Proviamo ora a definire un modello di probabilità per la scelta casuale di un punto sull'intervallo
$[a,b]$ in modo che la scelta sia uniforme. In questo caso abbiamo che $\Omega$ è non
numerabile in quanto esistono infiniti punti tra $a$ e $b$. Ne segue che la probabilità di
scegliere un punto in questo intervallo con una funzione di probabilità definita come in
precedenza non può che essere 0 poiché abbiamo infiniti casi possibili e un solo caso favorevole.

Potrebbe venirci in mente di definire la probabilità di scegliere un punto $x$ all'interno di
$[a,b]$ come la lunghezza dell'intervallo ($b-a$) ma ci si può facilmente accorgere che non
si riesce a definire in modo coerente la lunghezza di ogni sottoinsieme di $[a,b]$.

Per questo si introduce una $\sigma$-algebra più \emph{piccola} di $\mathcal{P}(\Omega)$,
detta degli \textbf{insiemi misurabili} che tratteremo più avanti.

\subsubsection{Serie}
Andiamo ora a capire trattare alcuni concetti di base, relativi alle serie, necessarie ad
inquadrare meglio la situazione.

\begin{definition}
	Sia $a_1, a_2, \dots$ una successione di termini, e sia
	\[ s_n = a_1 + \dots + a_n \]
	la somma parziale dei primi $n$ termini. Definiamo quest'ultima come \textbf{serie} se esiste
	il limite delle somme parziali
	\[ \sum_{n=1}^\infty a_n = \lim_{n \to \infty} \sum_{k=1}^n a_k = \lim_{n \to \infty} s_n \]
	Se esiste finito questo limite si dice che la serie \textbf{converge}.
\end{definition}

\begin{observation}
	Da qui è facile osservare che
	\[ a_n = s_n - s_{n-1} \]
	ed è chiaro che se esiste il limite
	\[ \lim_{n \to \infty} s_n \]
	il valore $a_n$ tende a zero per $n \to \infty$ ma non è vero il viceversa.
\end{observation}

Supponiamo ora il caso in cui $a_n \geq 0$ per ogni $n \in \N$ allora le somme parziali crescono
\[ s_n \leq s_{n+1} \]
In questo caso ha sempre senso parlare di limite poiché, per una successione del genere, vale
\[ \sum_{n=1}^\infty = \lim_{n \to \infty} \sum_{k=1}^n a_k \in [0, +\infty]  \]
Il fatto che esista sempre il limite non significa che la serie converga. Come detto poco fa, la
serie converge se il limite tende ad un numero reale finito.

\begin{definition}
	Se il limite
	\[ \lim_{n \to \infty} \sum_{n=1}^\infty |a_n| \]
	tende ad un numero reale finito si dice che la serie converge \emph{assolutamente}.
\end{definition}

\begin{theorem}
	Se una serie converge assolutamente allora converge.
\end{theorem}

Per le serie di termini positivi che convergono assolutamente vale anche una sorta di proprietà
\textbf{associativa} in cui si partizionano gli indici della serie in sottoinsiemi di $\N$
($A_1, A_2, \dots$) e vale
\[ \sum_{n=1}^\infty a_n = \sum_{n=1}^\infty \left( \sum_{k \in A_n} a_k \right) \]

Consideriamo ora due serie fondamentali di cui non facciamo la dimostrazione ma che ci saranno
molto utili in futuro:
\begin{itemize}
	\item \textbf{Serie geometrica}: se $|a| < 1$ allora vale
	      \[ \sum_{n=0}^\infty a^n = 1 + a + a^2 + \dots = \frac{1}{1 - a} \]
	\item \textbf{Sviluppo in serie dell'esponenziale}
	      \[ e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \]
\end{itemize}
