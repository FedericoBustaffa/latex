\section{Valore atteso, varianza e momenti}
Abbiamo definito la media campionaria di un insieme di dati come la loro media aritmetica
\[ \tilde{x} = \frac{1}{n} \sum_{i=1}^n x_i \]
per dare una misura del \emph{centro} della distribuzione dei dati. Abbiamo poi definito la
varianza campionaria
\[ \Var(x) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \tilde{x})^2 \]
come misura della \emph{dispersione} dei dati. Le stesse idee sono alla base dei concetti di
\textbf{valore atteso} e \textbf{varianza} di una variabile aleatoria, quest'ultimo inteso come
oggetto matematico che si propone di descrivere la \emph{casualità} dell'esito di un esperimento.

\subsection{Valore atteso}
Possiamo vedere il valore atteso come la quantità che indica attorno a quale valore la variabile
aleatoria è centrata.

Per una variabile aleatoria discreta che assume valori $x_1, x_2, \dots$ consideriamo come valore
atteso una media pesata di tali valori, dando come peso ad ogni valore la probabilità a questo
associata. Nel caso di variabili discrete che assumono infiniti valori, la media pesata diventa
una serie, di cui bisogna controllare la convergenza.

Per una variabile aleatoria con densità, rimpiazziamo la somma pesata della funzione di massa con
un integrale pesato della densità. Le considerazioni fatte per variabili discrete che possono
assumere infiniti valori sono analoghe per variabili con densità, per le quali dobbiamo effettuare
un controllo sui valori assumibili dall'integrale che definisce il valore atteso della variabile.

\begin{definition}
	Sia $X$ una variabile discreta con funzione di massa $p$, si dice che $X$ ammette valore atteso
	se
	\[ \sum_i |x_i| \cdot p(x_i) < +\infty \]
	e in tal caso si chiama \textbf{valore atteso} il numero
	\[ \E[X] = \sum_i x_i \cdot p(x_i) \]
	Sia poi $X$ con densità $f$, essa ammette valore atteso se
	\[ \int_{-\infty}^{+\infty} |x| \cdot f(x) dx < +\infty \]
	e in tal caso si chiama \textbf{valore atteso} il numero
	\[ \E[X] = \int_{-\infty}^{+\infty} x \cdot f(x) dx \]
\end{definition}

Notiamo che il valore atteso dipende solo dalla funzione di massa (nel caso discreto) o dalla
densità (nel caso con densità), quindi il valore atteso di $X$ dipende solo dalla legge $P_X$
di $X$.

\begin{example}
	Lanciamo un dado equilibrato e supponiamo di ricevere 2 euro se esce 6 e 1 euro se esce 4 o 5,
	0 altrimenti. Qual è il valore atteso del denaro che riceviamo?

	Prima di tutto definiamo una variabile aleatoria $X$ che può assumere come valori la quantità
	di denaro ricevuto in corrispondenza all'esito del lancio del dado. Dato che $X$ è concentrata
	su $\{ 0, 1, 2 \}$ dobbiamo calcolare la probabilità associata ad ognuno di questi valori
	\begin{gather*}
		P_X(0) = 1 / 2 \\[1ex]
		P_X(1) = 1 / 3 \\[1ex]
		P_X(2) = 1 / 6
	\end{gather*}
	A questo punto possiamo applicare la formula per il calcolo del valore atteso dalla quale
	otteniamo
	\[ \E[X] = 0 \cdot \frac{1}{2} + 1 \cdot \frac{1}{3} + 2 \cdot \frac{1}{6} = \frac{2}{3} \]
	ossia 0,67 euro vinti in media ad ogni lancio ripetuto del dado.
\end{example}

Vediamo ora come calcolare il valore atteso di una trasformazione di una variabile aleatoria $X$,
ossia di una nuova variabile $Y = g(X)$ con $g : \R \to \R$.

\begin{proposition}
	Sia $X$ discreta con funzione di massa $p$, la variabile $g(X)$ ammette valore atteso se
	$\sum_i |g(x_i)| \cdot p(x_i) < +\infty$, e in tal caso assume valore
	\[ \E[g(X)] = \sum_i g(x_i) \cdot p(x_i) \]
	Sia $X$ con densità $f$, la variabile $g(X)$ ha valore atteso se
	$\int_{-\infty}^{+\infty} |g(x)| \cdot f(x) dx < +\infty$, e in tal caso assume valore
	\[ \E[g(X)] = \int_{-\infty}^{+\infty} g(x) \cdot f(x) dx \]
	\begin{proof}
		Forniamo la dimostrazione per il caso discreto partendo da un caso particolare, ossia il
		caso in cui $g(x_i)$ sono tutti valori distinti. Allora la variabile aleatoria $g(X)$ ha
		come valori $g(x_1), g(x_2), \dots$ con probabilità rispettivamente $p(x_1), p(x_2), \dots$
		e quindi
		\[ \E[g(x)] = \sum_i g(x_i) \cdot p(x_i) \]
		Per dimostrare il caso generale partiamo da un sottocaso, ossia quello in cui $g \geq 0$.
		Abbiamo che $Y = g(x)$ assume valori $y_1, y_2, \dots$. Consideriamo ora gli insiemi
		\[ A_i = \{ j | g(x_j) = y_i \} \]
		e osserviamo che
		\[ P_Y(y_i) = P(g(X) = y_i) = P(X = x_j) \]
		per qualche $j \in A_i$. Questa probabilità la si riscrive come
		\[ P(X = x_j) = \sum_{j \in A_i} P_X (x_j) \]
		quindi
		\begin{multline*}
			\E[Y] = \sum_i y_i \cdot p_Y(y_i) =
			\sum_i y_i \left( \sum_{j \in A_i} p_X(x_j) \right) \\
			= \sum_i \left( \sum_{j \in A_i} g(x_j) \cdot p_X (x_j) \right) =
			\sum_j g(x_j) \cdot p_X (x_j)
		\end{multline*}
		Dato che $A_i$ è una partizione di tutti gli indici $j$. Il caso più generale si ottiene
		osservando che $g = g^+ - g^-$ dove
		\begin{align*}
			g^+ = & \max \{g,0\} \\
			g^- = & \max\{-g,0\}
		\end{align*}
	\end{proof}
\end{proposition}

\begin{example}
	Calcolare il valore atteso del quadrato dell'esito del lancio di un dado equilibrato. Prima di
	tutto definiamo la variabile aleatoria $X$ che definisce l'esito del lancio del dado. Abbiamo
	quindi $P_X(k) = 1/6$ per ogni $k \in \{1, \dots, 6\}$. Dobbiamo calcolare quindi $\E[X^2]$.
	\[
		\E[X^2] = \sum_i x_i^2 P(X = x_i) = \sum_{k=1}^6 k^2 \cdot \frac{1}{6}
		= \frac{91}{6} = 15.16
	\]
\end{example}

\begin{example}
	Sia $X \sim U((0,1))$ e $Y = X^2$, calcolare la densità $f_Y$ di $Y$ e $\E[Y]$. Notiamo che
	$Y = g(X)$ con $g(x) = x^2$ e $X$ ha densità
	\[
		f_X(x) = \begin{cases}
			\dfrac{1}{1-0} = 1 & x \in (0,1)    \\
			0                  & x \notin (0,1)
		\end{cases}
	\]
	In particolare $g : (0,1) \to (0,1)$ è $C^1$ invertibile con inversa
	\[ h(y) = \sqrt{y} \]
	che è $C^1$ e la sua derivata è $h'(x) = \frac{1}{2 \sqrt{y}}$ con $y \in (0,1)$. Quindi
	applicando la formula del cambio di variabile ottenendo che $Y$ ha densità
	\begin{align*}
		f_Y (y) = & \begin{cases}
			            f_X (h(y)) |h'(y)| & y \in (0,1)    \\
			            0                  & y \notin (0,1)
		            \end{cases}                  \\
		=         & \begin{cases}
			            \dfrac{1}{2 \sqrt{y}} & y \in (0,1)    \\
			            0                     & y \notin (0,1)
		            \end{cases}
	\end{align*}
	Calcoliamo quindi il valore atteso di $Y$. Il primo metodo è il seguente
	\[ \E[Y] = \int_{-\infty}^{+\infty} x^2 f_X (x) dx = \int_0^1 x^2 dx = \frac{1}{3} x^3 \]
	da valutare tra 1 e 0 e che quindi fa $1/3$.
\end{example}

\begin{observation}
	Quando $X \geq 0$, allora si può sempre definire $\E[X] \in [0, +\infty)$ come
	\[
		\E[X] = \begin{cases}
			\displaystyle\sum_i x_i \cdot p(x_i)                  & X \text{ discreta}    \\[3ex]
			\displaystyle\int_{-\infty}^{+\infty} x \cdot f(x) dx & X \text{ con densità}
		\end{cases}
	\]
\end{observation}

\begin{observation}
	Formule analoghe valgono per $\E[g(X,Y)]$, nel caso discreto abbiamo quindi che $g(X, Y)$
	ammette valore atteso se
	\[ \sum_{i,j} |g(x_i, y_j)| \cdot P_{(X,Y)} (x_i, y_j) < +\infty \]
	e, in tal caso assume valore
	\[ \E[g(X,Y)] = \sum_{i,j} g(x_i, y_j) \cdot P_{(X,Y)} (x_i, y_j) \]
	Nel caso con densità abbiamo invece che $g(X,Y)$ ammette valore atteso se
	\[ \iint |g(x,y)| \cdot f (x,y) dx dy < +\infty \]
	e in tal caso assume valore
	\[ \E[g(X, Y)] = \iint g(x, y) \cdot f(x,y) dx dy \]
\end{observation}

Introduciamo ora alcune proprietà del valore atteso, utili quando lavoriamo con più variabili
aleatorie. Siano $X$ e $Y$ variabili aleatorie che ammettono valore atteso, allora $X+Y$ ha valore
atteso e valgono le seguenti proprietà
\begin{align*}
	\E[X+Y] =         & \E[X] + \E[Y]                 \\
	\E[aX + b] =      & a \E[X] + b      & a,b \in \R \\
	|\E[X]| \leq      & \E[|X|]                       \\
	X \geq 0 \implies & \E[X] \geq 0                  \\
	X \geq Y \implies & \E[X] \geq \E[Y]
\end{align*}
\begin{proof}
	Dimostriamo la prima formula nel caso discreto assumendo che $X+Y$ abbia valore atteso
	senza verificarlo. Per farlo usiamo la formula per il valore atteso di $g(X,Y)$ con
	$g(X,Y) = X+Y$
	\begin{align*}
		\E[X+Y] = & \sum_{i,j} g(x_i, y_j) \cdot P_{(X, Y)} (x_i, y_j)                    \\
		=         & \sum_{i,j} (x_i + y_j) \cdot P_{(X,Y)} (x_i, y_j)                     \\
		=         & \sum_{i,j} x_i \cdot P_{(X,Y)} (x_i, y_j) +
		\sum_{i,j} y_j \cdot P_{(X,Y)} (x_i, y_j)                                         \\
		=         & \sum_i x_i \sum_j P_{(X,Y)} (x_i, y_j) +
		\sum_j y_j \sum_i P_{(X,Y)} (x_i, y_j)                                            \\
		=         & \sum_i x_i \cdot P_X(x_i) + \sum_j y_j \cdot P_Y(y_j) = \E[X] + \E[Y]
	\end{align*}
\end{proof}

Se consideriamo invece due variabili aleatorie $X$ e $Y$, non è detto che $X \cdot Y$ abbia valore
atteso.

\begin{proposition}
	Siano $X$ e $Y$ due variabili indipendenti che ammettono valore atteso, allora anche $X\cdot Y$
	ammette valore atteso e vale
	\[ \E[X \cdot Y] = \E[X] \cdot \E[Y] \]
	\begin{proof}
		Anche in questo caso svolgiamo la dimostrazione per quanto riguarda il caso discreto. Per
		prima cosa si verifica che $X \cdot Y$ ammette valore atteso. Assumendo che il primo passo
		sia verificato, proviamo a calcolare il valore atteso di $\E[g(X,Y)]$ dove $g(X,Y)=xy$
		\begin{align*}
			\E[X \cdot Y] = & \sum_{i,j} x_i \cdot y_j \cdot P_{(X,Y)} (x_i, y_j)        \\
			=               & \sum_{i,j} x_i \cdot y_j \cdot P_X(x_i) \cdot P_Y(y_j)     \\
			=               & \sum_i x_i \cdot P_X (x_i) \cdot \sum_j y_j \cdot P_Y(y_j) \\
			=               & \E[X] \cdot \E[Y]
		\end{align*}
	\end{proof}
\end{proposition}

\begin{corollary}
	Siano $X$ e $Y$ indipendenti e $h,k : \R \to \R$, con $h(X)$ e $k(Y)$ che ammettono valore
	atteso. Allora anche $h(X) \cdot k(Y)$ ha valore atteso e vale
	\[ \E[h(X) \cdot k(Y)] = \E[h(X)] \cdot \E[k(Y)] \]
	\begin{proof}
		Se $X$ e $Y$ sono indipendenti, allora $h(X)$ e $k(Y)$ sono indipendenti e quindi si usa
		il risultato precedente.
	\end{proof}
\end{corollary}

\subsection{Momenti}
I \textbf{momenti} di una variabile aleatoria descrivono alcune caratteristiche di tale variabile
come ad esempio la loro variazione o quanto questi sono addensati intorno a determinati valori.

\begin{definition}
	Diciamo che $X$ ammette \textbf{momento} di ordine $n$ se vale
	\[ \E[|X|^n] < +\infty \]
	e, in tal caso, chiamiamo momento di ordine $n$ la quantità
	\[ \E[X^n] \]
\end{definition}

Se $n=1$ troviamo quello che si chiama \textbf{momento primo} che equivale al valore atteso. Il
momento, in generale è un indice di quanto le \textbf{code} della distribuzioni sono \emph{pesanti}.

\begin{example}
	Sia $\beta > 1$ un parametro e sia $X$ variabile aleatoria con densità
	\[
		f(x) = \begin{cases}
			(\beta - 1) \cdot x^{-\beta} & x > 1    \\
			0                            & x \leq 1
		\end{cases}
	\]
	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[
					font=\footnotesize,
					width=10cm,
					height=5cm,
					axis lines = center,
					xlabel = $x$,
					ylabel = $y$,
					xtick = {-5, -3, -1, 1, 3, 5},
					ytick = {0.5, 1},
					ymin = -0.2, ymax = 1.2,
					xmin = -5, xmax = 5,
					grid = both,
					grid style = dashed,
					legend pos = north west,
					enlargelimits
				]


				\addplot [
					domain=-5:1,
					samples=100,
					thick,
					color=red
				]
				{0};

				\addplot [
					name path=f,
					domain=1:5,
					samples=100,
					thick,
					color=red,
				]
				{2 * x^(-3)};
			\end{axis}
		\end{tikzpicture}
	\end{center}
	Nel grafico $\beta = 3$ ma, in generale, più $\beta$ è grande, più la funzione va velocemente
	a 0. Ecco che il parametro $\beta$ determina quanto la coda della distribuzione sia
	\emph{pesante} (valori bassi di $\beta$) o \emph{leggera} (valori alti di $\beta$).
	Verifichiamo ora il momento di ordine $n$ considerando $g(x) = |x|^n \geq 0$ e dunque
	\begin{align*}
		\E[g(x)] = & \int g(x) \cdot f(x) dx                              \\
		=          & \int_1^{+\infty} x^n \cdot (\beta - 1) x^{-\beta} dx \\
		=          & \int_{1}^{+\infty} (\beta-1) \cdot x^{-\beta+n} dx
	\end{align*}
	Ecco che qui abbiamo due possibili casi
	\[
		\E[g(x)] = \begin{cases}
			-\frac{\beta-1}{\beta-n-1} \cdot x^{-\beta+n+1} \Big|_1^{+\infty}
			                                          & -\beta+n+1 \neq 0 \\[2ex]
			(\beta-1) \cdot \log(x) \Big|_1^{+\infty} & -\beta+n+1=0
		\end{cases}
	\]
	Ecco che nel caso in cui $-\beta+n+1 < 0$ abbiamo che il valore atteso vale
	\[ \frac{\beta-1}{\beta-n-1} \]
	nel caso $-\beta+n+1 = 0$ abbiamo che $\log(+\infty) = +\infty$ e quindi il valore atteso è
	$+\infty$, nel caso di $-\beta+n+1 > 0$ abbiamo che l'esponente di $x$ nella della prima
	equazione e positivo e dunque, per $x \to +\infty$, il valore atteso è $+\infty$. Concludiamo
	che $X$ ammette momento di ordine $n$ se e solo se $-\beta+n+1 < 0$ ovvero se e solo se
	\[ n < \beta - 1 \]
	Deduciamo quindi che, quanto più grande è $\beta$ (e quindi quanto più sono leggere le code)
	tanti di più sono i momenti che possiamo ammettere.
\end{example}

\begin{proposition}
	Se $X$ ammette momento di ordine $n$, allora ammette momento di ordine $m$ per ogni $m \leq n$.
\end{proposition}

\begin{proposition}[Disuguaglianza di Markov]\label{prop: markov}
	Sia $X$ una variabile aleatoria a valori non negativi e sia $a>0$, allora
	\[ P(X > a) \leq \frac{\E[X]}{a} \]
	\begin{proof}
		Introduciamo la seguente variabile aleatoria $Z : \Omega \to \R$
		\[
			Z = \begin{cases}
				a & \text{su } \{ X > a \} \subseteq \Omega    \\
				0 & \text{su } \{ X \leq a \} \subseteq \Omega
			\end{cases}
		\]
		Vediamo che sull'insieme $\{ X > a \}$ abbiamo che $Z = a$ e, in particolare $Z \leq X$.
		Sull'altro insieme abbiamo che $Z = 0$ ma $X \geq 0$ e quindi $Z \leq X$ su $\Omega$.
		Vale quindi che
		\[ \E[X] \geq \E[Z] = a \cdot P(Z = a) + 0 \cdot P(Z = 0) = a \cdot P(X \geq a) \]
	\end{proof}
\end{proposition}

\begin{corollary}
	Se $X$ ammette momento di ordine $n$, allora
	\[ P(|X| > a) \leq \frac{\E[|X|^n]}{a^n} \]
	per ogni $a > 0$.
\end{corollary}

\begin{proposition}[Disuguaglianza di Schwartz]
	Siano $X$ e $Y$ due variabili aleatorie, allora
	\[ \E[|XY|] \leq \sqrt{\E[|X|^2]} \cdot \sqrt{\E[|Y|^2]} \]
	Possiamo dire che $X \cdot Y$ ammette valore atteso se $X$ e $Y$ ammettono momento secondo.
\end{proposition}

\begin{example}
	Consideriamo 2 lanci di un dado equilibrato e vogliamo calcolare i valori attesi di somma e
	prodotto. Chiamiamo $X$ l'esito del primo lancio e $Y$ l'esito del secondo lancio. Iniziamo
	con il calcolare il valore atteso della somma
	\[ \E[X + Y] = \E[X] + \E[Y] = \frac{7}{2} + \frac{7}{2} = 7 \]
	Calcoliamo ora il valore atteso del prodotto, assumendo che i lanci del dado siano prove
	ripetute indipendenti
	\[ \E[X \cdot Y] = \E[X] \cdot \E[Y] = \frac{7}{2} \cdot \frac{7}{2} = \frac{49}{4} = 12.25 \]
	Quando $X$ assume un numero finito di valori ammette momento di ogni ordine.
\end{example}

\begin{example}
	Sia $S$ una popolazione e sia $X : S \to \R$ una variabile che rappresenta un carattere
	discreto di un certo individuo della popolazione. L'estrazione di un individuo da $S$ è
	modellizzata dal modello uniforme, $\Omega = S$, $\F = \mathcal{P}(\Omega)$ e $P$ è uniforme.
	Abbiamo quindi che
	\[
		\E[X] = \sum_i x_i \cdot P(X = x_i) =
		\sum_i x_i \cdot \frac{\# \{\omega \in S | X(\omega) = x_i\}}{\# S}
	\]
	Questo equivale alla \textbf{frequenza relativa} di $X = x_i$ su tutta la popolazione e quindi
	$\E[X]$ è la media campionaria su tutta la popolazione e non su un singolo campione.
\end{example}

\subsection{Varianza}
D'ora in poi supporremo che le variabili aleatorie che trattiamo abbiano momento secondo.
Analogamente al caso della varianza in statistica descrittiva, la \textbf{varianza} di una
variabile aleatoria $X$ misura la \emph{dispersione} di $X$ attorno al valore atteso $\E[X]$. La
varianza di $X$ è la media pesata del quadrato degli scarti di $X$ da $\E[X]$.

\begin{definition}
	Data $X$ con momento secondo, si chiama \textbf{varianza} di $X$ la quantità
	\[ \Var(X) = \E[(X - \E[X])^2] \]
	Si chiama \textbf{scarto quadratico medio} o \textbf{deviazione standard} la quantità
	\[ \sigma(X) = \sqrt{\Var(X)} \]
\end{definition}

\begin{observation}
	La varianza di $X$ dipende solo dalla legge $P_X$.
\end{observation}

\begin{observation}
	Sviluppando il quadrato
	\[ (X - \E[X])^2 = X^2 + \E[X]^2 - 2 X \E[X] \]
	otteniamo
	\[ \Var(X) = \E[X^2] - \E[X]^2 \]
	Inoltre vale
	\[ \Var(aX + b) = a^2 \Var(X) \]
\end{observation}

\begin{example}
	Calcoliamo ora la varianza del lancio di un dado data la variabile $X$ che rappresenta l'esito
	di un lancio.
	\[ \Var(X) = \E[X^2] - \E[X]^2 = \frac{91}{6} - \left(\frac{7}{2}\right)^2 = \frac{35}{12} \]
\end{example}

\begin{proposition}[Disuguaglianza di Chebyshev]
	Sia $X$ con momento secondo e sia $d > 0$, allora
	\[ P(|X - \E[X]| \geq d) \leq \frac{\Var(X)}{d^2} \]
	possiamo vedere questo come una stima quantitativa della dispersione tramite la varianza.
	\begin{proof}
		Possiamo riscrivere il termine a sinistra dell'equazione precedente come
		\[ P(|X - \E[X]| \geq d) = P((X - \E[X])^2 \geq d^2) \]
		A questo punto, applicando la \hyperref[prop: markov]{disuguaglianza di Markov} otteniamo
		che
		\[ P((X - \E[X])^2 \geq d^2) \leq \frac{\E[(X - \E[X])^2]}{d^2} \]
		a questo punto usiamo la definizione di varianza per ottenere
		\[ \frac{\E[(X - \E[X])^2]}{d^2} = \frac{\Var(X)}{d^2} \]
	\end{proof}
\end{proposition}

In particolare, quest'ultimo risultato ci dice che se la varianza è nulla allora la variabile
aleatoria è costante a meno di un insieme trascurabile. Vale quindi
\[ \Var(X) = 0 \Longleftrightarrow X = k \]
dove $k$ è una costante e quindi vale anche
\[ \Var(X) = 0 \Longleftrightarrow P(X - \E[X] \neq 0) = 1 \]

\begin{example}
	Consideriamo una popolazione $S$ e $X : S \to \R$ (discreta) che rappresenta il carattere di un
	individuo della popolazione. In questo caso $\Var(X)$ è la varianza empirica ma su tutta la
	popolazione.
\end{example}