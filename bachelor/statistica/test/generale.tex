\chapter{Test statistici}
Nel capitolo precedente abbiamo cercato di definire e trovare degli intervalli aleatori entro i
quali un certa caratteristica della popolazione cade con probabilità alta. I test statistici
cercano invece di capire quanto e se una o più caratteristiche del campione siano
\textbf{compatibili} con le reali caratteristiche della popolazione.

Pianificare un test significa formulare un'ipotesi su un parametro della distribuzione e
pianificare un esperimento per accettare o rifiutare l'ipotesi. La risposta non è mai una verità
e viene fornita con un opportuno livello di fiducia.

\section{Concetti generali}
Sia $X$ una variabile aleatoria con distribuzione $P_\theta$, con $\theta$ parametro non noto e
sia $X_1, \dots, X_n$ un campione i.i.d. di $X$. Un'\textbf{ipotesi statistica} è un'affermazione
sul parametro $\theta$. Formalmente, per formulare quest'ipotesi, si divide l'insieme $\Theta$ dei
parametri in due:
\begin{itemize}
	\item $\Theta_0$ è l'insieme dei parametri dell'ipotesi, detta \textbf{ipotesi nulla} $H_0$.
	\item $\Theta_1 = \Theta \backslash \Theta_0$ è l'insieme dei parametri
	      dell'\textbf{ipotesi alternativa} $H_1$.
\end{itemize}
Un test statistico è una procedura per accettare o rifiutare l'ipotesi nulla $H_0$, sulla base dei
dati del campione $X_1, \dots, X_n$:
\begin{itemize}
	\item Si \textbf{accetta} $H_0$ se i valori assunti dal campione sono \emph{compatibili} con
	      $H_0$.
	\item Si \textbf{rifiuta} $H_0$, in favore di $H_1$, se, con un alto grado di fiducia, i valori
	      assunti dal campione non sono compatibili con $H_0$, c'è quindi \textbf{evidenza statistica}
	      contro $H_0$.
\end{itemize}

\begin{observation}
	Notiamo che c'è un'\textbf{asimmetria} tra le ipotesi nulla e alternativa:
	\begin{itemize}
		\item Rifiutare $H_0$ significa che c'è un'evidenza, dai dati, contro $H_0$.
		\item Accettare $H_0$ non significa che c'è evidenza per $H_0$ ma solo che i dati sono
		      compatibili con $H_0$ e quindi non c'è evidenza contro $H_0$.
	\end{itemize}
\end{observation}

\subsection{Regione critica}
Per formulare il test, si deve determinare l'insieme dei risultati che portano a rifiutare
l'ipotesi nulla. Questo insieme si identifica come un sottoinsieme $C \subset \Omega$ ed è
detto \textbf{regione critica}. Il complementare $C^c$ è detto \textbf{regione di accettazione}.
Come vedremo, $C$ viene scelto in modo tale che i suoi valori siano
\begin{itemize}
	\item \textbf{Estremi} sotto $H_0$: per ogni $\theta \in \Theta_0$, la probabilità
	      $P_\theta (C)$ è piccola.
	\item \textbf{Compatibili} con $H_1$: il verificarsi di $C$ è un indicazione per $H_1$.
\end{itemize}
La scelta di $C$ dipende dalla distribuzione $P_\theta$ per $\theta \in \Theta_0$ e dalla forma
delle ipotesi (se ad esempio $\Theta_0$ è una semiretta a destra, a sinistra oppure se è un singolo
punto).

\subsection{Potenza e curva operativa}
Il risultato del test è soggetto a due tipi di errore:
\begin{itemize}
	\item Di \textbf{prima specie} quando si rifiuta $H_0$ e questa è vera.
	\item Di \textbf{seconda specie} quando si accetta $H_0$ e questa è falsa.
\end{itemize}

\begin{definition}
	Fissato $\alpha \in (0,1)$, si dice che il test è di \textbf{livello} $\alpha$ se, per ogni
	$\theta \in \Theta_0$, vale
	\[ P_\theta (C) \leq \alpha \]
\end{definition}

Quindi fissare un livello per un test significa fissare un limite superiore per gli errori di
prima specie, scegliendo $C$ in modo tale da soddisfare $P_\theta (C) \leq \alpha$ per ogni
$\theta \in \Theta_0$. Questo perché $P_\theta(C)$ è la probabilità di rifiutare quando l'ipotesi
nulla è vera.

La scelta di $\alpha$ (in genere 0.05 o 0.01) dipende dal \textbf{grado di fiducia} che chiediamo
per rifiutare $H_0$. Più piccolo è $\alpha$, maggiore è l'evidenza che richiediamo per rifiutare
$H_0$.

\begin{definition}
	Si chiama \textbf{potenza} del test la funzione che associa a $\theta \in \Theta$ la
	probabilità $P_\theta(C)$. Si chiama invece \textbf{curva operativa} la funzione che associa
	a $\theta \in \Theta$ la probabilità $P_\theta (C^c) = 1 - P_\theta(C)$ e si indica spesso con
	$\beta(\theta)$.
	\begin{itemize}
		\item Per $\theta \in \Theta_1$, il valore $\beta(\theta)$ della curva operativa in
		      $\theta$, equivale alla probabilità di accettare $H_0$ quando $\theta \in \Theta_1$
		      è nell'ipotesi alternativa. Equivale quindi alla probabilità di errore di seconda
		      specie per il dato $\theta \in \Theta_1$.
		\item La potenza di $1 - \beta(\theta)$ è la probabilità di rifiutare $H_0$ quando questa
		      è falsa. Rappresenta cioè la capacità di accorgersi che $H_0$ non è soddisfatta.
	\end{itemize}
\end{definition}

Nella formulazione di un test vorremmo che il test abbia livello basso (bassa probabilità di errori
di prima specie) e potenza alta (bassa probabilità di errori di seconda specie).

Queste richieste sono tuttavia in contrapposizione, infatti un basso livello del test vuol dire una
richiesta di maggiore evidenza per rifiutare $H_0$ e quindi un maggiore rischio di errore di
seconda specie, quindi bassa potenza.

\subsection{p-value}
Il metodo classico di impostazione di un test è
\begin{enumerate}
	\item Fissare un livello $\alpha$ a priori.
	\item Scegliere la regione critica $C$ in modo da soddsifare $P_\theta(C) \leq \alpha$ per ogni
	      $\theta \in \Theta_0$.
\end{enumerate}
La scelta di $\alpha$ ovviamente influenza la scelta di $C$ e di conseguenza il risultato del test:
più piccolo è $\alpha$ (maggiore è l'evidenza richiesta per rifiutare), più piccola è la regione
critica. In particolare, se rifiutiamo ad un certo livello $\alpha$, allora rifiutiamo anche al
livello $\alpha' > \alpha$, mentre potremmo accettare per un livello inferiore ad $\alpha$.

\subsubsection{Calcolo del p-value}
Per ovviare alla dipendenza dell'esito del test da $\alpha$, viene usato il metodo del $p$-value.
A differenza della regione critica $C$, che è fissata a priori indipendentemente dall'esito del
campione, il $p$-value dipende dalla realizzazione $(x_1, \dots, x_n)$ del campione
$(X_1, \dots, X_n)$.

Informalmente il $p$-value di un dato $(x_1, \dots, x_n)$ è la probabilità $\bar{\alpha}$
nell'ipotesi $H_0$ di ottenere dati più estremi (rispetto ad $H_0$) di $(x_1, \dots, x_n)$.

\begin{definition}
	Data $(x_1, \dots, x_n)$ realizzazione del campione $(X_1, \dots, X_n)$ si chiama
	\textbf{$p$-value} di $(x_1, \dots, x_n)$ il valore
	\[ \bar{\alpha} = \bar{\alpha} (x_1, \dots, x_n) \]
	tale che, se il livello $\alpha$ del test è $\alpha < \bar{\alpha}$, l'ipotesi viene accettata
	a livello $\alpha$, mentre se $\alpha > \bar{\alpha}$, l'ipotesi viene rifiutata a livello
	$\alpha$.
\end{definition}

Il $p$-value sintetizza in un unico numero la \emph{plausibilità} dell'ipotesi $H_0$ e l'esito del
test al variare di $\alpha$. Il $p$-value offre come esito quantitativo tra 0 e 1, un'informazione
più ricca della semplice dicotomia accetto/rifiuto (indipendente dal livello $\alpha$).

In pratica, se il $p$-value è molto basso, l'ipotesi $H_0$ è decisamente poco plausibile, se invece
il $p$-value è alto allora $H_0$ è molto plausibile. Per valori intermedi, il $p$-value, ci dice
quanto forte è l'indicazione contro $H_0$ (più basso è il $p$-value, più forte è l'indicazione
contro $H_0$).

\begin{example}
	In un controllo qualità su un campione di 1000 pezzi, 30 risultano difettosi. Vogliamo quindi
	verificare se la percentuale di pezzi difettosi è non superiore al 2\%. Ci poniamo quindi sotto
	le ipotesi
	\[ H_0 : \theta \leq 0.02 \qquad H_1 : \theta > 0.02 \]
	e formuliamo un test di livello $\alpha = 0.05$ che ci farà rifiutare $H_0$ se
	\[ P_\theta (\bar{X} > d) \leq 0.05 \]
	In questo caso il $p$-value dei dati ottenuti equivale alla probabilità, assumendo
	$\theta \leq 0.02$, di trovare almeno 30 pezzi difettosi su 1000.
\end{example}