\section{Matrici e vettori}

\begin{definition}
	Dati due interi positivi $m, n$, una \textbf{matrice} $m \times n$ a coefficienti in $\K$ è una
	griglia composta da $m$ righe e $n$ colonne in cui in ogni posizione c'è un elemento di $\K$:
	\[
		A = \begin{pmatrix}
			a_{11} & a_{12} & \dots & a_{1n} \\
			a_{21} & a_{22} & \dots & \dots  \\
			\dots  & \dots  & \dots & \dots  \\
			a_{m1} & \dots  & \dots & a_{mn}
		\end{pmatrix}
	\]
	Per indicare l'elemento che si trova nella riga $i$-esima dall'alto e nella colonna $j$-esima da sinistra
	viene indicato con $a_{ij}$. Spesso per indicare la matrice $A$ useremo la notazione $A = (a_{ij})$ e per
	ricordare le dimensioni della matrice scriveremo:
	\[
		A = (a_{ij})_{\substack{
					i = 1, 2, \dots, m \\
					j = 1, 2, \dots, n}}
	\]
\end{definition}

\begin{definition}
	Dati due interi positivi $m$ ed $n$, definiamo l'insieme di tutte le matrici $m \times n$ a
	coefficienti in $\K$ indicandolo con $\Mat_{m \times n} (\K)$.
\end{definition}

\begin{definition}
	Sull'insieme $\Mat_{m \times n} (\K)$ possiamo definire la \textbf{somma} e il
	\textbf{prodotto per scalare}. Date due matrici $A, B \in \Mat_{m \times n} (\K)$ e dato uno scalare
	$k \in \K$, definiamo:
	\begin{itemize}
		\item La \textbf{matrice somma} $A + B = C$, il cui generico coefficiente nella $i$-esima riga e
		      $j$-esima colonna si ottiene sommando i coefficienti nella stessa posizione indicata da $(i, j)$
		      di $A$ e di $B$. Ovvero per ogni $i \leq m$ e per ogni $j \leq n$ ho che $c_{ij} = a_{ij} + b_{ij}$.
		\item La \textbf{matrice prodotto per scalare} $k \cdot A = D$, il cui generico coefficiente nella
		      $i$-esima riga e $j$-esima colonna si ottiene moltiplicando lo scalare $k$ per il coefficiente
		      di $A$ in posizione $(i, j)$. Ovvero per ogni $i \leq m$ e per ogni $j \leq n$ ho che
		      $d_{ij} = k \cdot a_{ij}$.
	\end{itemize}
\end{definition}

Esiste un'altra operazione, si tratta del \emph{prodotto righe per colonne}. Per definire tale prodotto è
importante l'ordine in cui si considerano le due matrici (quindi non vale la proprità commutativa). Inoltre
tale operazione è definita solo quando il numero di colonne di $A$ è uguale al numero di righe di $B$.

\begin{definition}
	Data una matrice $A = (a_{ij}) \in \Mat_{m \times n} (\K)$ e una matrice
	$B = (b_{st}) \in \Mat_{n \times k} (\K)$, il \textbf{prodotto riga per colonna} $AB$, è la matrice
	$C = (c_{rh}) \in \Mat_{m \times k} (\K)$, i cui coefficienti, per ogni $r, h$, sono definiti come
	segue:
	\[ c_{rh} = a_{r1} b_{1h} + a_{r2} b_{2h} + \cdots + a_{rn} b_{nh} \]
\end{definition}

\begin{example}
	Consideriamo la matrice $A \in \Mat_{2 \times 3}(\K)$:
	\[
		A = \begin{pmatrix}
			1 & 2 & 4 \\
			0 & 6 & 3
		\end{pmatrix}
	\]
	e la matrice $B \in \Mat_{3 \times 3}(\K)$:
	\[
		B = \begin{pmatrix}
			2 & 2 & 2  \\
			5 & 6 & -8 \\
			0 & 1 & 0
		\end{pmatrix}
	\]
	La definizione ci dice che possiamo definire $C = AB$ e che $C$ è la matrice di $\Mat_{2 \times 3}(\K)$
	i cui coefficienti sono ottenuti come segue:
	\begin{align*}
		c_{11} = & 1 \cdot 2 + 2 \cdot 5 + 4 \cdot 0 =    & 12  \\
		c_{12} = & 1 \cdot 2 + 2 \cdot 6 + 4 \cdot 1 =    & 18  \\
		c_{13} = & 1 \cdot 2 + 2 \cdot (-8) + 4 \cdot 0 = & -14 \\
		c_{21} = & 0 \cdot 2 + 6 \cdot 5 + 3 \cdot 0 =    & 30  \\
		c_{22} = & 0 \cdot 2 + 6 \cdot 6 + 3 \cdot 1 =    & 39  \\
		c_{23} = & 0 \cdot 2 + 6 \cdot (-8) + 3 \cdot 0 = & -48
	\end{align*}
	E dunque si ha:
	\[
		AB = C = \begin{pmatrix}
			12 & 18 & -14 \\
			30 & 39 & -48
		\end{pmatrix}
	\]
\end{example}

\begin{definition}
	Data un'applicazione lineare $L$ da uno spazio vettoriale $V$ di dimensione $n$ ad uno spazio vettoriale
	$W$ di dimensione $m$, si dice \textbf{matrice associata} all'applicazione lineare $L$ nelle basi
	$\{e_1, e_2, \dots, e_n\}$ di $V$ e $\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ di $W$, la seguente
	matrice di $m$ righe ed $n$ colonne:
	\[
		[L]_{\substack{
					e_1, e_2, \dots, e_n\\
					\epsilon_1, \epsilon_2, \dots, \epsilon_m
				}} = \begin{pmatrix}
			a_{11} & a_{12} & \dots & a_{1n} \\
			a_{21} & a_{22} & \dots & \dots  \\
			\dots  & \dots  & \dots & \dots  \\
			a_{m1} & \dots  & \dots & a_{mn}
		\end{pmatrix}
	\]
	dove $\{e_1, e_2, \dots, e_n\}$ è la base di partenza e $\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ è
	la base di arrivo.
\end{definition}

Sarà tutto più chiaro con un esempio che vedremo tra poco. In ogni caso, per alleggerire la notazione, si
possono omettere le basi, tuttavia si deve ricordare che la matrice $[L]$ associata all'applicazione lineare
$L$, non dipende solo da $L$ stessa, ma anche dalle basi scelte per $V$ e $W$.

\begin{example}
	Consideriamo gli spazi vettoriali $\R^4$ con la sua base
	\[
		v_1 = \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 0
		\end{pmatrix} \quad
		v_2 = \begin{pmatrix}
			0 \\ 1 \\ 1 \\ 0
		\end{pmatrix} \quad
		v_3 = \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 1
		\end{pmatrix} \quad
		v_4 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 1
		\end{pmatrix}
	\]
	e $\R^3$ con la sua base
	\[
		w_1 = \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} \quad
		w_2 = \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} \quad
		w_3 = \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}
	\]
	Quel che vogliamo fare è scrivere la matrice associata all'applicazione lineare
	\[
		L \begin{pmatrix}
			x \\ y \\ z \\ w
		\end{pmatrix} = \begin{pmatrix}
			x + y + z \\
			y - z     \\
			x + w
		\end{pmatrix}
	\]
	Procediamo calcolando l'immagine di ognuna delle componenti della base di $\R^4$
	\begin{align*}
		L \begin{pmatrix}
			  1 \\ 1 \\ 0 \\ 0
		  \end{pmatrix} =
		\begin{pmatrix}
			2 \\ 1 \\ 1
		\end{pmatrix} \quad
		L \begin{pmatrix}
			  0 \\ 1 \\ 1 \\ 0
		  \end{pmatrix} =
		\begin{pmatrix}
			2 \\ 0 \\ 0
		\end{pmatrix} \\
		L \begin{pmatrix}
			  0 \\ 0 \\ 1 \\ 1
		  \end{pmatrix} =
		\begin{pmatrix}
			1 \\ -1 \\ 1
		\end{pmatrix} \quad
		L \begin{pmatrix}
			  0 \\ 0 \\ 0 \\ 1
		  \end{pmatrix} =
		\begin{pmatrix}
			0 \\ 0 \\ 1
		\end{pmatrix}
	\end{align*}
	Ora dobbiamo esprimere i risultati trovati come combinazioni lineari della base di
	$\R^3$.
	\begin{gather*}
		\begin{pmatrix}
			2 \\ 1 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			2 \\ 0 \\ 0
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			1 \\ -1 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			0 \\ 0 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}
	\end{gather*}
	Ottengo dunque quattro sistemi.
	\begin{gather*}
		\begin{cases}
			a + b      & = 2 \\
			b          & = 1 \\
			a + b + 2c & = 1
		\end{cases}
		\quad
		\begin{cases}
			a + b      & = 2 \\
			b          & = 0 \\
			a + b + 2c & = 0
		\end{cases} \\
		\\
		\begin{cases}
			a + b      & = 1  \\
			b          & = -1 \\
			a + b + 2c & = 1
		\end{cases}
		\quad
		\begin{cases}
			a + b      & = 0 \\
			b          & = 0 \\
			a + b + 2c & = 2
		\end{cases}
	\end{gather*}
	Se li risolvo ottengo
	\begin{gather*}
		\begin{cases}
			a & = 1  \\
			b & = 1  \\
			c & = -1
		\end{cases}
		\quad
		\begin{cases}
			a & = 2  \\
			b & = 0  \\
			c & = -1
		\end{cases} \\
		\\
		\begin{cases}
			a & = 2  \\
			b & = -1 \\
			c & = 0
		\end{cases}
		\quad
		\begin{cases}
			a & = 0 \\
			b & = 0 \\
			c & = 1
		\end{cases}
	\end{gather*}
	Ora non devo fare altro che prendere i vettori
	\[
		\begin{pmatrix}
			1 \\ 1 \\ -1
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			2 \\ 0 \\ -1
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			2 \\ -1 \\ 0
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			0 \\ 0 \\ -1
		\end{pmatrix}
	\]
	e formare la matrice associata all'applicazione lineare $L$.
	\[
		[L]_{\substack{v_1, v_2, v_3, v_4 \\
					w_1, w_2, w_3}} =
		\begin{pmatrix}
			1  & 2  & 2  & 0  \\
			1  & 0  & -1 & 0  \\
			-1 & -1 & 0  & -1
		\end{pmatrix}
	\]
\end{example}

\begin{observation}
	Dati due spazi vettoriali $V$ e $W$, esiste una sola applicazione lineare da $V$ a $W$ la cui matrice
	associata è indipendente dalle basi scelte. Questa è l'\emph{applicazione nulla}
	$\mathcal{O} : V \rightarrow W$ che manda ogni $v \in V$ in $O \in W$. Qualunque siano le basi scelte, la
	matrice associata avrà tutti i coefficienti uguali a $0$.
\end{observation}

\begin{observation}
	Consideriamo l'applicazione \emph{identità} $I : V \rightarrow V$, che lascia fisso ogni elemento di
	$v: I(v) = v$, $\forall v \in V$, e fissiamo la base $\B$ di $V$. Si verifica che la matrice
	$[I] = (a_{ij})$, associata ad $I$ rispetto a $\B$, sia in arrivo che in partenza, è la matrice
	quadrata di formato $n \times n$ che ha tutti i coefficienti uguali a $0$ eccetto quelli sulla diagonale,
	che sono invece uguali a $1$.  Tale matrice è l'elemento neutro rispetto alla moltiplicazione riga per
	colonna in $\Mat_{n \times n}(\K)$.

	In seguito useremo solo il simbolo $I$ per indicare sia la matrice identità che	l'applicazione lineare
	$I$.
\end{observation}