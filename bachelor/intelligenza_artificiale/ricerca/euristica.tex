\chapter{Ricerca euristica} \label{chapter: euristica}
La ricerca esaustiva, per problemi con complessit\`a esponenziale, non \`e praticabile.
Quello che di solito viene fatto \`e usare la conoscenza del problema e l'esperienza
per riconoscere i cammini pi\`u promettenti, si fa cio\`e una stima del costo futuro.

Si introduce cos\`i il concetto di \textbf{conoscenza euristica}, che aiuta a fare scelte
\emph{oculate}. In questo modo si riduce la ricerca, si trova una \emph{buona} soluzione
in tempi accettabili e, sotto certe condizioni, garantisce completezza e ottimalit\`a.

\section{Funzione di valutazione euristica}
Per fare ci\`o di cui abbiamo parlato in precedenza dobbiamo introdurre una funzione
$f$, detta \textbf{funzione di valutazione euristica} definita come segue:
\[ f(n) = g(n) + h(n) \]
dove
\begin{itemize}
	\item $g(n)$ \`e il costo del cammino per arrivare al nodo $n$ dal nodo di partenza.
	\item $h(n)$ \`e una stima del costo del cammino per raggiungere il nodo \emph{goal}
	      dal nodo $n$ secondo l'euristica scelta.
	\item $f(n)$ \`e il costo stimato del cammino per arrivare dal nodo di partenza
	      al nodo \emph{goal} passando da $n$.
\end{itemize}

\begin{example}
	Se volessi trovare il percorso migliore per muovermi da una citt\`a $A$ ad una
	citt\`a $B$ passando per delle tappe intermedie potrei decidere di scegliere la tappa in
	successiva base a quanto dista da $B$ in linea d'aria. In questo caso la distanza in linea
	d'aria sar\`a la nostra euristica $h$.
\end{example}

\section{Ricerca Best-First}
Questo algoritmo utilizza UC come algoritmo per la ricerca ma stavolta si fa una stima di
costo per la coda con priorit\`a. In sostanza, ad ogni passo, si sceglie il nodo sulla
frontiera per cui il valore di $f$ \`e il migliore (il nodo pi\`u promettente).

In alcuni casi per valore \emph{migliore} si intende il valore pi\`u alto mentre in altri
casi si intende quello pi\`u basso, tutto dipende dal tipo di problema.

\subsubsection{Ricerca Greedy Best-First}
Se usiamo solo $h$ per la scelta del nodo ovvero se $f(n) = h(n)$ abbiamo la variante
Greedy Best-First in cui si basa la scelta interamente sul valore dell'euristica.

\section{Algoritmo A}
\begin{definition}
	Un \textbf{algoritmo A} \`e un algoritmo Best-First con una funzione di valutazione
	dello stato del tipo:
	\[ f(n) = g(n) + h(n) \quad \text{con } h(n) \geq 0 \wedge h(goal) = 0 \]
\end{definition}
I casi particolari di un algoritmo A sono
\begin{itemize}
	\item Ricerca di costo uniforme (UC) se $h(n) = 0$.
	\item Greedy Best-First se $g(n) = 0$.
\end{itemize}

\begin{theorem}
	L'algoritmo A \`e completo se
	\[ g(n) \geq d(n) \cdot \epsilon \quad \]
	dove $d(n)$ \`e la profondit\`a del nodo $n$ nell'albero di ricerca e $\epsilon > 0$
	\`e il costo minimo di un arco.
	\begin{proof}
		Sia $\{ n_0, n_1, ..., n', ..., n_k \}$ un cammino soluzione. Sia $n'$ un nodo
		della frontiera su un cammino soluzione allora $n'$ prima o poi sar\`a espanso.

		Infatti esistono solo un numero finito di nodi $x$ che possono essere aggiunti
		alla frontiera con $f(x) \leq f(n')$

		Quindi se non si trova una soluzione prima, $n'$ verr\`a espanso e i suoi
		successori verranno aggiunti alla frontiera. Tra questi anche il successore sul
		cammino soluzione.

		Il ragionamento si pu\`o ripetere fino a dimostrare che anche il nodo \emph{goal}
		verr\`a selezionato per l'espansione. Tuttavia l'algoritmo termina una volta
		giunto al nodo \emph{goal}.
	\end{proof}
\end{theorem}

\section{Algoritmo A*}
Prima di definire l'algoritmo dobbiamo introdurre una funzione di valutazione ideale
(\textbf{oracolo}) definita come segue
\[ f^*(n) = g^*(n) + h^*(n) \]
dove
\begin{itemize}
	\item $g^*(n)$ \`e il costo del cammino minimo dalla radice a $n$.
	\item $h^*(n)$ \`e il costo del cammino minimo da $n$ al nodo \emph{goal}.
	\item $f^*(n)$ \`e il costo del cammino minimo da radice a \emph{goal}, attraverso $n$.
\end{itemize}
Normalmente $g(n) \geq g^*(n)$ e $h(n)$ \`e una stima di $h^*(n)$.

\subsubsection{Sottostima}
Ho una \textbf{sottostima} quando \[ h(n) \leq h^*(n) \] ovvero quando il valore di $h$ \`e
\emph{migliore} di quello di $h^*$ ma non pu\`o tuttavia essere quello \emph{reale}.

\begin{example}
	Se vogliamo muoverci da una citt√† ad un'altra la distanza fra le due sar\`a sicuramente
	minore in linea d'aria ma nella pratica posso muovermi solo lungo le strade. Nel caso
	in cui ci sia una strada perfettamente dritta che corrisponde alla linea d'aria tra le
	due citt\`a avr\`o che
	\[ h(n) = h^*(n) \]
\end{example}

\subsubsection{Sovrastima}
Ho una \textbf{sovrastima} quando \[ h(n) \geq h^*(n) \] ovvero quando il valore di $h$ \`e
\emph{peggiore} di quello di $h^*$.

\begin{definition}
	Un'euristica $h$ \`e detta \textbf{ammissibile} se per ogni $n$, vale
	\[ h(n) \leq h^*(n) \]
	cio\`e se $h$ \`e una sottostima.
\end{definition}

\begin{definition}
	Un \textbf{algoritmo A*} \`e un algoritmo A in cui $h$ \`e una funzione euristica
	ammissibile.
\end{definition}

\begin{theorem}
	Gli algoritmi A* sono ottimali.
\end{theorem}

\begin{corollary}
	BF e UC sono ottimali ($h(n) = 0$).
\end{corollary}

\subsection{Osservazioni su A*}
Rispetto alla Greedy Best-First la componente $g$ fa s\`i che si abbandonino cammini che
vanno troppo in profondit\`a.

Ma come scegliere $h$ ?
\begin{itemize}
	\item Una sottostima $h$ pu\`o farci compiere lavoro inutile per\`o non ci fa perdere
	      l'ottimo.
	\item Una sovrastima, invece, potrebbe farci compiere meno lavoro ma col rischio di perdere
	      l'ottimo.
\end{itemize}

\subsection{Ottimalit\`a di A*}
\begin{itemize}
	\item Nel caso di ricerca su albero, l'uso di un'euristica ammissibile \`e sufficiente a
	      garantire l'ottimalit\`a di A*.
	\item Nel caso di ricerca su grafo serve una propriet\`a pi\`u forte: la
	      \textbf{consistenza}. La consistenza fa s\`i che si eviti di scartare candidati
	      ottimi. Per farlo cerchiamo condizioni in grado di garantire che il primo nodo
	      espanso sia il migliore.
\end{itemize}

\begin{definition}
	Un'euristica \`e detta \textbf{consistente} se
	\begin{itemize}
		\item $h(goal) = 0$
		\item $\forall n \quad h(n) \leq c(n, a, n') + h(n')$ dove $c$ \`e il costo
		      dell'azione $a$ per arrivare da $n$ a $n'$ ($n'$ \`e un successore di $n$).
		\item Segue che $f(n) \leq f(n')$.
	\end{itemize}
\end{definition}

\begin{theorem}
	Se $h$ \`e consistente la $f$ non decresce mai lungo i cammini (euristica
	\textbf{monot\`ona}).
	\begin{proof}
		Se \[ h(n) \leq c(n, a, n') + h(n') \] allora
		\[ g(n) + h(n) \leq g(n) + c(n, a, n') + h(n') \]
		ma siccome
		\[ g(n) + c(n, a, n') = g(n') \] allora
		\[ g(n) + h(n) \leq g(n') + h(n') \] che equivale a dire
		\[ f(n) \leq f(n') \]
	\end{proof}
\end{theorem}

\subsubsection{Euristiche monot\`one}
\begin{theorem}
	Un'euristica monot\`ona \`e ammissibile
\end{theorem}
Le euristiche monot\`one garantiscono che la soluzione meno costosa venga trovata per prima
e quindi sono ottimali anche nella ricerca su grafo. Questo perch\'e
\begin{itemize}
	\item Non si devono recuperare tra gli antenati nodi con costo minore.
	\item La lista degli esplorati ci garantisce che lo stato gi\`a esplorato sia sul cammino
	      ottimo quindi, posso evitare di inserire il nodo corrente senza perdere
	      l'ottimalit\`a.
	\item Sostituisco un nodo gi\`a nella frontiera con uno che ha lo stesso stato ma costo
	      del cammino minore.
\end{itemize}
Ogni volta che A* seleziona un nodo $n$ per l'espansione, il cammino ottimo a tale nodo \`e stato
trovato. Se cos\`i non fosse, ci sarebbe un un altro nodo $m$ della frontiera sul cammino
ottimo, con $f(m)$ minore. Ma ci\`o non \`e possibile perch\'e tale nodo sarebbe gi\`a stato
espanso.

Quando A* seleziona il nodo \emph{goal} ho il cammino ottimo.

\subsection{Vantaggi di A*}
A* risulta vantaggioso per tre motivi fondamentalmente:
\begin{itemize}
	\item Espande tutti i nodi con $f(n) < C^*$ dove $C^*$ \`e il costo minimo.
	\item Espande alcuni nodi con $f(n) = C^*$.
	\item Non espande alcun nodo con $f(n) > C^*$. Alcuni nodi non vengono proprio considerati
	      per l'espansione (\emph{pruning}). Per tagliare pi\`u rami dell'albero di ricerca cerco
	      euristiche con valore pi\`u alto possibile (pi\`u informate).
\end{itemize}

\subsection{Bilancio su A*}
I punti a favore sono
\begin{itemize}
	\item A* \`e completo.
	\item A* con un'euristica monot\`ona \`e ottimale.
	\item A* \`e ottimamente efficiente, ovvero, a parit\`a di euristica, nessun altro algoritmo
	      espande meno nodi.
\end{itemize}
I problemi sono
\begin{itemize}
	\item La scelta/costruzione dell'euristiche.
	\item La complessit\`a in spazio, che \`e $O(b^{d+1})$ per via della frontiera.
\end{itemize}

\section{Costruzione e valutazione di euristiche}
A parit\`a di ammissibilit\`a, un'euristica pu\`o essere pi\`u efficiente di un'altra nel
trovare il cammino soluzione migliore. Questo dipende da quanto \`e informata l'euristica.
Pi\`u l'euristica \`e informata pi\`u \`e efficiente
\begin{itemize}
	\item Se $h(n) = 0$ non sono niente.
	\item $h^*(n)$ \`e l'oracolo che sa gi\`a il cammino minimo.
\end{itemize}

\begin{theorem}
	Siano $h_1, h_2$ due euristiche tali che \[ h_1 \leq h_2 \] allora i nodi espansi da
	A* con $h_2$ sono un sottoinsieme di quelli espansi da A* con $h_1$.
\end{theorem}

\begin{theorem}
	Siano $h_1, h_2$ due euristiche tali che \[ h_1 \leq h_2 \] allora A* con $h_2$ \`e
	almeno efficiente quanto A* con $h_1$
\end{theorem}
In generale un'euristica pi\`u informata riduce lo spazio di ricerca ma \`e, tipicamente,
pi\`u costosa da calcolare.

\subsection{Misura del potere euristico}
Per riuscire a valutare meglio algoritmi di ricerca con euristica introduciamo il
\textbf{fattore di diramazione effettivo (b*)}. Tale valore rappresenta il fattore di diramazione
di un albero uniforme con $N + 1$ nodi ed \`e la soluzione dell'equazione
\[ N + 1 = b^* + (b^*)^2 + \dots + (b^*)^d \] dove $N$ \`e il numero di nodi generati e $d$ \`e
la profondit\`a della soluzione.

In genere una buona euristica ha una $b^*$ abbastanza vicino a 1 ($< 1.5$).

\subsubsection{Capacit\`a di esplorazione}
\`E importante sapere che, migliorando di poco l'euristica, si migliora di molto la
\textbf{capacit\`a di esplorazione} (si va pi\`u in profondit\`a pi\`u in fretta).

\subsection{Costruire un'euristica ammissibile}
Di seguito sono elencate brevemente alcune strategie per ottenere euristiche ammissibili.

\subsubsection{Rilassamento del problema}
Si posso rilassare i vincoli del problema per ottenere sottostime.

\subsubsection{Massimizzazione di euristiche}
Se si hanno una serie di euristiche ammissibili, senza che nessuna ne domini un'altra
allora conviene prendere il massimo dei loro valori.

\subsubsection{Pattern disgiunti}
Posso creare un'euristica per la risoluzione di un sottoproblema, ottenendo cos\`i una
sottostima del costo del problema intero. A questo punto salvo ogni istanza del
sottoproblema in un database di pattern (con relativo costo della soluzione) e uso il
database per trovare un'euristica ammissibile.

Possiamo fare lo stesso per pi\`u sottoproblemi ottenendo altre euristiche
ammissibili. Se prendo quella con valore massimo ho sempre un'euristica ammissibile.

Non \`e tuttavia possibile sommarle per ottenere un'euristica ancora pi\`u accurata. Questo
perch\'e le soluzioni ai sottoproblemi interferiscono tra loro e perch\'e in generale la somma
delle euristiche non \`e ammissibile.

Ecco che ci vengono in aiuto i \textbf{database di pattern disgiunti} che ci permettono di
sommare i costi e sono anche molto efficienti.

\subsubsection{Costruzione tramite apprendimento}
Si possono apprendere nuove euristiche tramite l'esperienza, si fa cio\`e girare il programma
per ottenere informazioni utili alla costruzione dell'euristica.

\subsubsection{Combinazione di euristiche}
Si possono combinare pi\`u euristiche come combinazione lineare
\[ h(n) = c_1 x_1(n) + \dots + c_k x_k(n) \]
Il peso dei coefficienti pu\`o essere regolato sempre con l'\emph{esperienza}. Vale che $h(goal) = 0$
ma ammissibilit\`a e consistenza non sono automatiche.

\section{Algoritmi euristici ottimizzati in spazio}
\subsection{Beam Search}
\`E una variante della Best-First che tiene, ad ogni passo, solo i $k$ nodi pi\`u
promettenti, dove $k$ \`e l'\emph{ampiezza del raggio} (beam). Anche se pi\`u efficiente
in spazio la Beam Search non \`e completa.

\subsection{IDA*}
Questo algoritmo combina A* con ID (ricerca non informata). Si fa in sostanza una ricerca in
profondit\`a con un limite dato dal valore della funzione $f$ (e non dalla profondit\`a).
Tale limite viene aumentato ad ogni iterazione, fino a trovare la soluzione.

\subsubsection{Di quanto incrementare \emph{f}-limit ?}
La scelta dell'incremento \`e fondamentale per garantire l'ottimalit\`a, ma come
sceglierlo ?
\begin{itemize}
	\item Nel caso di costo fisso delle azioni, il limite viene incrementato del costo
	      delle azioni.
	\item Nel caso di costo variabile delle azioni ho due opzioni:
	      \begin{itemize}
		      \item Prendo il costo minimo.
		      \item Ad ogni passo prendo il valore minimo delle $f$ scartate
		            all'iterazione precedente.
	      \end{itemize}
\end{itemize}
L'algoritmo IDA* \`e completo e ottimale se sono rispettate le regole di incremento di $f$-limit
viste poco fa. La complessit\`a in spazio \`e $O(bd)$.